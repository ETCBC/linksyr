{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link pericopes to Peshitta and Syrnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import rmtree\n",
    "import re\n",
    "import collections\n",
    "from tf.app import use\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 'peshitta'\n",
    "S = 'syrnt'\n",
    "A = {P: None, S: None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = os.path.expanduser('~/github')\n",
    "ORG = 'etcbc'\n",
    "REPO = 'linksyr'\n",
    "\n",
    "LECTIONARY_DATA = 'data/lectionaries'\n",
    "DATA_FILE = 'pericopes.csv'\n",
    "DATA_PATH = f'{BASE}/{ORG}/{REPO}/{LECTIONARY_DATA}/{DATA_FILE}'\n",
    "\n",
    "TEMP = '_temp'\n",
    "TEMP_PATH = f'{BASE}/{ORG}/{REPO}/{TEMP}'\n",
    "PERI_RAW_FILE = 'periraw.txt'\n",
    "PERI_RAW_PATH = f'{TEMP_PATH}/{PERI_RAW_FILE}'\n",
    "PERI_FILE = 'peri.txt'\n",
    "PERI_PATH = f'{TEMP_PATH}/{PERI_FILE}'\n",
    "ERROR_FILE = 'error.txt'\n",
    "ERROR_PATH = f'{TEMP_PATH}/{ERROR_FILE}'\n",
    "\n",
    "TF_BASE = f'{BASE}/{ORG}/{REPO}/data/tf/lectio'\n",
    "VERSION = {\n",
    "  P: '0.1',\n",
    "  S: '0.1',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the TF data for both volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF app is up-to-date.\n",
      "Using annotation/app-peshitta commit 1f3f47a5154f5be012f5c42d050baca70a6c7e48 (=latest)\n",
      "  in /Users/dirk/text-fabric-data/__apps__/peshitta.\n",
      "Using etcbc/peshitta/tf - 0.1 r0.4 in /Users/dirk/text-fabric-data\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Documentation:** <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs\" title=\"provenance of Peshitta (Old Testament)\">PESHITTA</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Writing/Syriac\" title=\"('Syriac characters and transcriptions',)\">Character table</a> <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#transcription.md\" title=\"PESHITTA feature documentation\">Feature docs</a> <a target=\"_blank\" href=\"https://github.com/annotation/app-peshitta\" title=\"peshitta API documentation\">peshitta API</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/\" title=\"text-fabric-api\">Text-Fabric API 7.3.12</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Use/Search/\" title=\"Search Templates Introduction and Reference\">Search Reference</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>Loaded features</b>:</summary>\n",
       "<p><b>Peshitta (Old Testament)</b>: <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#book\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/book.tf\">book</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#book@ll\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/book@en.tf\">book@ll</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#chapter\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/chapter.tf\">chapter</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#otype\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/otype.tf\">otype</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#trailer\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/trailer.tf\">trailer</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#trailer_etcbc\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/trailer_etcbc.tf\">trailer_etcbc</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#verse\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/verse.tf\">verse</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#witness\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/witness.tf\">witness</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#word\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/word.tf\">word</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#word_etcbc\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/word_etcbc.tf\">word_etcbc</a>  <b><i><a target=\"_blank\" href=\"https://github.com/etcbc/peshitta/blob/master/docs/transcription-0.1.md#oslots\" title=\"/Users/dirk/text-fabric-data/etcbc/peshitta/tf/0.1/oslots.tf\">oslots</a></i></b> </p></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.otf?raw=true');\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".sy,.sy a:visited,.sy a:link {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".syb,.syb a:visited,.syb a:link {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF app is up-to-date.\n",
      "Using annotation/app-syrnt commit d8cce973438848a1bf7e4f4ab62b2d480206ca9b (=latest)\n",
      "  in /Users/dirk/text-fabric-data/__apps__/syrnt.\n",
      "Using etcbc/syrnt/tf - 0.1 r0.3 in /Users/dirk/text-fabric-data\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Documentation:** <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs\" title=\"provenance of SyrNT\">SYRNT</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Writing/Syriac\" title=\"('Syriac characters and transcriptions',)\">Character table</a> <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#transcription.md\" title=\"SYRNT feature documentation\">Feature docs</a> <a target=\"_blank\" href=\"https://github.com/annotation/app-syrnt\" title=\"syrnt API documentation\">syrnt API</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/\" title=\"text-fabric-api\">Text-Fabric API 7.3.12</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Use/Search/\" title=\"Search Templates Introduction and Reference\">Search Reference</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>Loaded features</b>:</summary>\n",
       "<p><b>SyrNT</b>: <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#book\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/book.tf\">book</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#book@ll\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/book@en.tf\">book@ll</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#chapter\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/chapter.tf\">chapter</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#demcat\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/demcat.tf\">demcat</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#fmhdot\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/fmhdot.tf\">fmhdot</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#gn\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/gn.tf\">gn</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#lexeme\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/lexeme.tf\">lexeme</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#lexeme_etcbc\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/lexeme_etcbc.tf\">lexeme_etcbc</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#lexeme_sedra\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/lexeme_sedra.tf\">lexeme_sedra</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#nmtyp\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/nmtyp.tf\">nmtyp</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#ntyp\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/ntyp.tf\">ntyp</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#nu\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/nu.tf\">nu</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#otype\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/otype.tf\">otype</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#prefix\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/prefix.tf\">prefix</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#prefix_etcbc\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/prefix_etcbc.tf\">prefix_etcbc</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#prefix_sedra\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/prefix_sedra.tf\">prefix_sedra</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#prtyp\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/prtyp.tf\">prtyp</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#ps\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/ps.tf\">ps</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#ptctyp\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/ptctyp.tf\">ptctyp</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#root\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/root.tf\">root</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#root_etcbc\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/root_etcbc.tf\">root_etcbc</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#root_sedra\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/root_sedra.tf\">root_sedra</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#seyame\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/seyame.tf\">seyame</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#sfcontract\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/sfcontract.tf\">sfcontract</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#sfgn\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/sfgn.tf\">sfgn</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#sfnu\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/sfnu.tf\">sfnu</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#sfps\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/sfps.tf\">sfps</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#sp\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/sp.tf\">sp</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#st\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/st.tf\">st</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#stem\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/stem.tf\">stem</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#stem_etcbc\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/stem_etcbc.tf\">stem_etcbc</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#stem_sedra\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/stem_sedra.tf\">stem_sedra</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#suffix\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/suffix.tf\">suffix</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#suffix_etcbc\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/suffix_etcbc.tf\">suffix_etcbc</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#suffix_sedra\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/suffix_sedra.tf\">suffix_sedra</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#verse\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/verse.tf\">verse</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#vs\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/vs.tf\">vs</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#vt\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/vt.tf\">vt</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#word\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/word.tf\">word</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#word_etcbc\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/word_etcbc.tf\">word_etcbc</a>  <a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#word_sedra\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/word_sedra.tf\">word_sedra</a>  <b><i><a target=\"_blank\" href=\"https://github.com/etcbc/syrnt/blob/master/docs/transcription-0.1.md#oslots\" title=\"/Users/dirk/text-fabric-data/etcbc/syrnt/tf/0.1/oslots.tf\">oslots</a></i></b> </p></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.otf?raw=true');\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".sy,.sy a:visited,.sy a:link {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".syb,.syb a:visited,.syb a:link {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".sp,.sp a:visited,.sp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".lexeme {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataSource in A:\n",
    "  A[dataSource] = use(dataSource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the TF handles easily available for both volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.3.12\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "1 features found and 0 ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Warp feature \"otype\" not found in\n",
      "/Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1/\n",
      "  0.00s Warp feature \"oslots\" not found in\n",
      "/Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Warp feature \"otext\" not found. Working without Text-API\n",
      "\n",
      "This is Text-Fabric 7.3.12\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "1 features found and 0 ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Warp feature \"otype\" not found in\n",
      "/Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1/\n",
      "  0.00s Warp feature \"oslots\" not found in\n",
      "/Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Warp feature \"otext\" not found. Working without Text-API\n",
      "\n"
     ]
    }
   ],
   "source": [
    "api = {}\n",
    "F = {}\n",
    "T = {}\n",
    "L = {}\n",
    "TF = {}\n",
    "tfDir = {}\n",
    "verseNodes = {}\n",
    "sortNodes = {}\n",
    "for volume in A:\n",
    "  thisApi = A[volume].api\n",
    "  api[volume] = thisApi\n",
    "  F[volume] = thisApi.F\n",
    "  T[volume] = thisApi.T\n",
    "  L[volume] = thisApi.L\n",
    "  tfDir[volume] = f'{TF_BASE}/{volume}/{VERSION[volume]}'\n",
    "  TF[volume] = Fabric(locations=tfDir[volume])\n",
    "  sortNodes[volume] = thisApi.sortNodes\n",
    "  verseNodes[volume] = thisApi.F.otype.s('verse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a mapping from each book acronym to\n",
    "\n",
    "* the volume in which the book resides\n",
    "* its node number in that volume,\n",
    "* its English name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book acronyms in the lectionary data is slightly different from those in the TF data.\n",
    "Here is a mapping from lectionary book acronyms to TF book names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookMapping = {\n",
    "  P: {\n",
    "    '1Chr': 'Chr1',\n",
    "    '2Chr': 'Chr2',\n",
    "    '1Mc': 'Mc1_A',\n",
    "    '1Rg': 'Rg1',\n",
    "    '2Rg': 'Rg2',\n",
    "    '1Sm': 'Sm1',\n",
    "    '2Sm': 'Sm2',\n",
    "    '4Ezra': 'Esr4',\n",
    "    'Am': 'Am',\n",
    "    'ApBar': 'ApBar',\n",
    "    'Bar': 'Bar',\n",
    "    'Bel_Dr': 'BelDr',\n",
    "    'Ct': 'Ct',\n",
    "    'Dn': 'Dn',\n",
    "    'Dt': 'Dt',\n",
    "    'Ec': 'Ec',\n",
    "    'EpBar': 'EpBar_A',\n",
    "    'Ex': 'Ex',\n",
    "    'Ez': 'Ez',\n",
    "    'Gn': 'Gn',\n",
    "    'Hb': 'Hb',\n",
    "    'Hg': 'Hg',\n",
    "    'Hs': 'Hs',\n",
    "    'Is': 'Is',\n",
    "    'Jb': 'Jb',\n",
    "    'Jd': 'Jd',\n",
    "    'Jl': 'Jl',\n",
    "    'Jon': 'Jon',\n",
    "    'Jr': 'Jr',\n",
    "    'Js': 'Jos',\n",
    "    'Lm': 'Thr',\n",
    "    'Lv': 'Lv',\n",
    "    'Mi': 'Mi',\n",
    "    'Ml': 'Ml',\n",
    "    'Na': 'Na',\n",
    "    'Nm': 'Nm',\n",
    "    'Ob': 'Ob',\n",
    "    'Pr': 'Pr',\n",
    "    'Ru': 'Ru',\n",
    "    'Sa': 'Sa',\n",
    "    'Sap': 'Sap',\n",
    "    'Sir': 'Sir',\n",
    "    'Su': 'Sus',\n",
    "    'Zf': 'Zf',\n",
    "  },\n",
    "  S: {\n",
    "    '1Cor': '1Cor',\n",
    "    '2Cor': '2Cor',\n",
    "    '1Joh': '1John',\n",
    "    '1Petr': '1Peter',\n",
    "    '2Petr': '2Peter',\n",
    "    '1Thess': '1Thess',\n",
    "    '2Thess': '2Thess',\n",
    "    '1Tim': '1Tim',\n",
    "    '2Tim': '2Tim',\n",
    "    'Tim': '1Tim',\n",
    "    'Acts': 'Acts',\n",
    "    'Col': 'Col',\n",
    "    'Eph': 'Eph',\n",
    "    'Gal': 'Gal',\n",
    "    'Heb': 'Heb',\n",
    "    'Jas': 'James',\n",
    "    'Joh': 'John',\n",
    "    'Jude': 'Jude',\n",
    "    'Lk': 'Luke',\n",
    "    'Mat': 'Matt',\n",
    "    'Mk': 'Mark',\n",
    "    'Phil': 'Phil',\n",
    "    'Rom': 'Rom',\n",
    "    'Tit': 'Titus',\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a mapping from TF book names to TF book nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = {}\n",
    "for dataSource in A:\n",
    "  books[dataSource] = {F[dataSource].book.v(n): n for n in F[dataSource].otype.s('book')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we flatten the `bookMapping` above into a plain mapping from lectionary books to TF books.\n",
    "\n",
    "We retain the information of which book belongs to which volume (OT or NT) in `whatVolume`, keyed by\n",
    "the TF book name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookFromPeri = {}\n",
    "whatVolume = {}\n",
    "\n",
    "for volume in bookMapping:\n",
    "  for periAcro in bookMapping[volume]:\n",
    "    bookAcro = bookMapping[volume][periAcro]\n",
    "    bookFromPeri[periAcro] = bookAcro\n",
    "    whatVolume[bookAcro] = volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have a function that delivers for a lectionary acronym the volume, the TF book node, and the English book name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookInfo(bookAcro):\n",
    "  volume = whatVolume[bookAcro]\n",
    "  node = books[volume][bookAcro]\n",
    "  name = T[volume].bookName(node)\n",
    "  return (volume, node, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('peshitta', 427228, 'Genesis')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookInfo('Gn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('syrnt', 109641, 'Matthew')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookInfo('Matt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the lectionary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEMP_PATH):\n",
    "  os.makedirs(TEMP_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "  with open(DATA_PATH) as fh:\n",
    "    header = next(fh)\n",
    "    lines = list(fh)\n",
    "  header = {n: name for (n, name) in enumerate(header.rstrip('\\n').split(';'))}\n",
    "  lines = [line.rstrip('\\n').split(';') for line in lines]\n",
    "  return (header, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(header, lines) = readData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 = ﻿no. MS\n",
      " 1 = No.\n",
      " 2 = Pericope\n",
      " 3 = Intro\n",
      " 4 = Intro.Remarks\n",
      " 5 = Intro.Transl\n",
      " 6 = Thales\n",
      " 7 = Thales ID\n",
      " 8 = Intro.Fol.A\n",
      " 9 = \n",
      "10 = Intro.Col.A\n",
      "11 = Intro.Line.A\n",
      "12 = Intro.Fol.Z\n",
      "13 = Intro.Col.Z\n",
      "14 = Intro.Line.Z\n",
      "15 = Taksa\n",
      "16 = Taksa.Trans\n",
      "17 = Taksa.Remarks\n",
      "18 = Transl.remarks\n",
      "19 = Taksa.Fol.A\n",
      "20 = Taksa.Col.A\n",
      "21 = Taksa.Line.A\n",
      "22 = Taksa.Fol.Z\n",
      "23 = Taksa.Col.Z\n",
      "24 = Taksa.Line.Z\n",
      "25 = Taksa.Remarks\n",
      "26 = Siglum\n",
      "27 = Siglum\n",
      "28 = Link\n",
      "29 = Link\n",
      "30 = MS-List.link\n",
      "31 = Pericope.Fol.A\n",
      "32 = Pericope.Col.A\n",
      "33 = Pericope.Line.A\n",
      "34 = Pericope.Fol.Z\n",
      "35 = Pericope.Col.Z\n",
      "36 = Pericope.Line.Z\n",
      "37 = Cross reference (corpus) [to be filled in aut.]\n",
      "38 = Remarks Cross reference (corpus)\n",
      "39 = Abbreviation\n",
      "40 = Version\n",
      "41 = Version.Remarks\n",
      "42 = Version.Syriac\n",
      "43 = Version.Transl\n",
      "44 = Denomination\n",
      "45 = Literature\n",
      "46 = Literature.link\n",
      "47 = Codicology\n",
      "48 = Pericope.remarks\n",
      "49 = Ref.remarks.\n",
      "50 = Cross.ref.Lect\n",
      "51 = Transl.Cross.ref.\n",
      "52 = Addition before\n",
      "53 = Addition after\n",
      "54 = Addition.Fol.A\n",
      "55 = Addition.Col.A\n",
      "56 = Addition.Line.A\n",
      "57 = Addition.Fol.Z\n",
      "58 = Addition.Col.Z\n",
      "59 = Addition.Line.Z\n",
      "60 = Ref.Bible.MS\n",
      "61 = Other Remarks\n",
      "62 = Words.Margin\n",
      "63 = no. reading Dissertation K.D. Jenner\n",
      "64 = \n",
      "65 = Structure formula 1\n",
      "66 = Structure formula 2\n",
      "67 = Structure formula 3\n",
      "68 = Structure formula 4\n",
      "69 = Structure formula 5\n",
      "70 = Title lectionary MS\n",
      "71 = fol\n",
      "72 = col\n",
      "73 = line\n",
      "74 = fol\n",
      "75 = col\n",
      "76 = Line\n",
      "77 = Remarks on title\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(f'{n:>2} = {name}' for (n, name) in header.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿no. MS = 73\n",
      "No. = 073-0265\n",
      "Pericope = Acts#08:05-13.\n",
      "Intro = ‎‏ܦܪܟܣܝܣ‏‎\n",
      "Intro.Remarks = \n",
      "Intro.Transl = Acts\n",
      "Thales = \n",
      "Thales ID = \n",
      "Intro.Fol.A = 161b\n",
      " = \n",
      "Intro.Col.A = 2\n",
      "Intro.Line.A = 19\n",
      "Intro.Fol.Z = 161b\n",
      "Intro.Col.Z = 2\n",
      "Intro.Line.Z = 19\n",
      "Taksa = ‎‏ܬܘܒ ܛܟܣܐ ܥܠ ܚܕ̈ܒܫܒܐ ܐܚܪ̈ܢܐ ܬܡ̈ܢܝܐ ܕܩܝܡܬܐ ܡܫܲܒܚܬܐ‏‎\n",
      "Taksa.Trans = Furthermore, the order on Last First (Day) of the Week, the Eighth, of the praiseworthy Resurrection\n",
      "Taksa.Remarks = subrubr ‎‏ܛܟܣܐ ܩܕܡܝܐ ܕܩܝܡܬܐ ܡܲܐܚܝܢܝܬܐ‏‎ (12-13 - after a blank line) (The First Order of the live-giving Resurrection)\n",
      "Transl.remarks = The First Order of the live-giving Resurrection\n",
      "Taksa.Fol.A = 159b\n",
      "Taksa.Col.A = 1.\n",
      "Taksa.Line.A = 1.\n",
      "Taksa.Fol.Z = 159b\n",
      "Taksa.Col.Z = 1.\n",
      "Taksa.Line.Z = 11.\n",
      "Taksa.Remarks = \n",
      "Siglum = 16l1\n",
      "Siglum = 16l01\n",
      "Link = https://archive.org/stream/SMC1.1/SMC%201.1#page/n165/mode/1up\n",
      "Link = https://archive.org/stream/SMC1.1/SMC%201.1#page/n165/mode/1up\n",
      "MS-List.link = 16l01\n",
      "Pericope.Fol.A = 161b\n",
      "Pericope.Col.A = 2\n",
      "Pericope.Line.A = 19\n",
      "Pericope.Fol.Z = 162b\n",
      "Pericope.Col.Z = 1\n",
      "Pericope.Line.Z = 4\n",
      "Cross reference (corpus) [to be filled in aut.] = \n",
      "Remarks Cross reference (corpus) = \n",
      "Abbreviation = \n",
      "Version = P\n",
      "Version.Remarks = \n",
      "Version.Syriac = \n",
      "Version.Transl = \n",
      "Denomination = J\n",
      "Literature = \n",
      "Literature.link = \n",
      "Codicology = ?\n",
      "Pericope.remarks = \n",
      "Ref.remarks. = \n",
      "Cross.ref.Lect = \n",
      "Transl.Cross.ref. = \n",
      "Addition before = \n",
      "Addition after = \n",
      "Addition.Fol.A = \n",
      "Addition.Col.A = \n",
      "Addition.Line.A = \n",
      "Addition.Fol.Z = \n",
      "Addition.Col.Z = \n",
      "Addition.Line.Z = \n",
      "Ref.Bible.MS = \n",
      "Other Remarks = \n",
      "Words.Margin = \n",
      "no. reading Dissertation K.D. Jenner = \n",
      " = \n",
      "Structure formula 1 = \n",
      "Structure formula 2 = \n",
      "Structure formula 3 = \n",
      "Structure formula 4 = \n",
      "Structure formula 5 = \n",
      "Title lectionary MS = \n",
      "fol = \n",
      "col = \n",
      "line = \n",
      "fol = \n",
      "col = \n",
      "Line = \n",
      "Remarks on title = \n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(f'{header[n]} = {value}' for (n, value) in enumerate(lines[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pericope analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERICOPE_INDEX = 2\n",
    "VERSION_INDEX = 40\n",
    "P_VAL = 'P'\n",
    "P_INDEX = 2\n",
    "\n",
    "TAKSA = 15\n",
    "TAKSA_TR = 16 \n",
    "\n",
    "SIGLUM = 26\n",
    "LINK = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = {}\n",
    "\n",
    "with open(PERI_RAW_PATH, 'w') as fh:\n",
    "  for (ln, line) in enumerate(lines):\n",
    "    if line[VERSION_INDEX] != P_VAL:\n",
    "      continue\n",
    "    pericopeStr = line[P_INDEX]\n",
    "    raw[ln] = pericopeStr\n",
    "    fh.write(f'{ln:>5} {pericopeStr}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = {\n",
    "  855: ('01:03:', '01:03-'),\n",
    "  1209: ('Tit#03:', '+03:'),\n",
    "  1252: ('-10', ''),\n",
    "  1253: (')', ''),\n",
    "  1298: ('Is#01-01', 'Is#01:01'),\n",
    "  1350: ('Pr#2109', 'Pr#21:09'),\n",
    "  1425: ('-05-03', '-05:03'),\n",
    "  1549: ('12:09-09b', '12:09b'),\n",
    "  1697: ('12:09-09b', '12:09b'),\n",
    "  2142: ('12:09-09b', '12:09b'),\n",
    "  2353: ('12:09-09b', '12:09b'),\n",
    "  2617: ('12:09-09b', '12:09b'),\n",
    "  2858: ('12:09-09b', '12:09b'),\n",
    "  4447: ('12:09-09b', '12:09b'),\n",
    "  4681: ('12:09-09b', '12:09b'),\n",
    "  4837: ('12:09-09b', '12:09b'),\n",
    "  8692: ('12:09-09b', '12:09b'),\n",
    "  1955: (' + small fragments', ''),\n",
    "  2732: ('-10-37', '-37'),\n",
    "  3025: ('1Joh#03:02:17', '1Joh#03:02-17'),\n",
    "  3914: ('-17-21', '+17-21'),\n",
    "  4244: ('1-17.', ''),\n",
    "  4263: ('01-02', '01:01-02'),\n",
    "  4545: ('#24:-', '#24:2-'),\n",
    "  5196: ('Rom#09:10:17-18', 'Rom#10:17-18'),\n",
    "  5212: ('Acts#12:25-13-03', 'Acts#12:25-13:03'),\n",
    "  5261: ('Rom#07:07:16', 'Rom#07:07-16'),\n",
    "  6168: ('Dn#23', 'Dn#6:23'),\n",
    "  7964: ('{or Rom#:-13}', ''),\n",
    "  8896: ('Sa#04', 'Sa#08:04'),\n",
    "}\n",
    "skips = {\n",
    "  887,\n",
    "  1612,\n",
    "  1613,\n",
    "  2864,\n",
    "  4568,\n",
    "  4569,\n",
    "  6333,\n",
    "  7284,\n",
    "  7430,\n",
    "  7519,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exceptions) + len(skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = None\n",
    "# test = {3534, 3584}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "headingPat = r'\\s*[()]([^()]*[^()A-Za-z0-9:.?-]+[^()]*)[()]\\s*'\n",
    "headingRe = re.compile(headingPat)\n",
    "\n",
    "def headingRepl(match):\n",
    "  head = match.group(1).replace('/', '|').replace('-', '\\u2017')\n",
    "  return f'{{{head}}}'\n",
    "\n",
    "anglePat = r'\\s*<[^>]+>\\s*'\n",
    "angleRe = re.compile(anglePat)\n",
    "bracketPat = r'\\s*\\([^)]+\\)\\s*'\n",
    "bracketRe = re.compile(bracketPat)\n",
    "\n",
    "def simplify(x, ln):\n",
    "  trim = (\n",
    "    x\n",
    "    .replace('\\u200E', '')\n",
    "    .replace('\\u200F', '')\n",
    "    .replace('\\u2013', '-')\n",
    "    .replace('[', '')\n",
    "    .replace(']', '')\n",
    "    .replace('.', '')\n",
    "  )\n",
    "  trim = angleRe.sub('', trim)\n",
    "  trim = headingRe.sub(headingRepl, trim)\n",
    "  trim = bracketRe.sub('', trim)\n",
    "  trim = trim.replace('++', '')\n",
    "  trim = trim.replace('-?', '')\n",
    "  trim = trim.replace('?', '')\n",
    "  if ln in exceptions:\n",
    "    (offend, better) = exceptions[ln]\n",
    "    trim = trim.replace(offend, better)\n",
    "  return trim\n",
    "\n",
    "def sanitize(x):\n",
    "    return (\n",
    "        x\n",
    "        .strip()\n",
    "        .replace('\\u200E', '')\n",
    "        .replace('\\u200F', '')\n",
    "        .replace('\\u2013', '-')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePericopes(shape, prevData):\n",
    "  parts = shape.strip().strip('+').split('+')\n",
    "  result = []\n",
    "  for part in parts:\n",
    "    (good, data) = parsePericope(part, prevData)\n",
    "    if not good:\n",
    "      return (False, shape)\n",
    "    result.append(data)\n",
    "    prevData = data[-1]\n",
    "  return (True, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "referencePat = r'^([A-Za-z0-9_]+#)?[0-9]+'\n",
    "referenceRe = re.compile(referencePat)\n",
    "\n",
    "def parsePericope(shape, prevData):\n",
    "  shape = shape.strip().strip('-')\n",
    "  if not referenceRe.match(shape):\n",
    "    shape = shape.replace('-', '\\u2017')\n",
    "  parts = shape.split('-')\n",
    "  if len(parts) > 2:\n",
    "    return (False, shape)\n",
    "  if len(parts) == 1:\n",
    "    (good, data) = parseVerse(shape, prevData)\n",
    "    if good:\n",
    "      return (good, [data])\n",
    "    else:\n",
    "      return (good, shape)\n",
    "  result = []\n",
    "  for part in parts:\n",
    "    (good, data) = parseVerse(part, prevData)\n",
    "    if not good:\n",
    "      return (good, shape)\n",
    "    else:\n",
    "      result.append(data)\n",
    "      prevData = data\n",
    "  return (True, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "headPat = r'\\{([^\\)]+)\\}'\n",
    "headRe = re.compile(headPat)\n",
    "\n",
    "def stripHeading(shape):\n",
    "  takeWhole = False\n",
    "  match = headRe.search(shape)\n",
    "  if not match:\n",
    "    if not referenceRe.match(shape):\n",
    "      takeWhole = True\n",
    "    else:\n",
    "      return (shape, None, None)\n",
    "  head = shape if takeWhole else match.group(1)\n",
    "  head = head.replace('\\u2017', '-')\n",
    "  headParts = head.split('/' if takeWhole else '|', 1)\n",
    "  if len(headParts) == 1:\n",
    "    headParts = (head, None)\n",
    "  shape = '' if takeWhole else headRe.sub('', shape)\n",
    "  return (shape, *headParts)\n",
    "\n",
    "def parseVerse(shape, prevData):\n",
    "  book = None\n",
    "  chapter = None\n",
    "  verse = None\n",
    "  fullShape = shape.strip()\n",
    "  (shape, head1, head2) = stripHeading(fullShape)\n",
    "  if shape == '':\n",
    "    if prevData is None or len(prevData) < 3:\n",
    "      return (False, fullShape)\n",
    "    (book, chapter, verse) = prevData[0:3]\n",
    "    return (True, (book, chapter, verse, head1, head2))\n",
    "    \n",
    "  parts = [p.strip() for p in shape.split('#')]\n",
    "  chvh = None\n",
    "  if len(parts) > 2:\n",
    "    return (False, fullShape)\n",
    "  \n",
    "  chvh = shape if len(parts) == 1 else parts[1]\n",
    "  book = None if len(parts) == 1 else bookFromPeri[parts[0]]\n",
    "  \n",
    "  subparts = [sp.strip() for sp in chvh.split(':')]\n",
    "  if len(subparts) > 2:\n",
    "    return (False, fullShape)\n",
    "  \n",
    "  if len(subparts) == 1:\n",
    "    chapter = None\n",
    "    verse = chvh\n",
    "  else:\n",
    "    (chapter, verse) = subparts\n",
    "    \n",
    "  if book is None:\n",
    "    if prevData is None:\n",
    "      return (False, fullShape)\n",
    "    book = prevData[0]\n",
    "  if chapter is None:\n",
    "    if prevData is None or len(prevData) < 2:\n",
    "      return (False, fullShape)\n",
    "    chapter = prevData[1]\n",
    "  else:\n",
    "    chapter = chapter.lstrip('0')\n",
    "    if chapter == '':\n",
    "      chapter = 0\n",
    "    elif not chapter.isdigit():\n",
    "      return (False, fullShape)\n",
    "    else:\n",
    "      chapter = int(chapter)\n",
    "    if chapter == 0:\n",
    "      chapter = 1\n",
    "    \n",
    "  if verse is not None:\n",
    "    verse = verse.replace('a', '').replace('b', '').replace('f', '').lstrip('0')\n",
    "    if '/' in verse:\n",
    "      verse = verse.split('/', 1)[0]\n",
    "    if verse == 'end':\n",
    "      verse = None\n",
    "    else:\n",
    "      verse = verse.lstrip('0')\n",
    "      if verse == '':\n",
    "        verse = 0\n",
    "      elif not verse.isdigit():\n",
    "        return (False, fullShape)\n",
    "      else:\n",
    "        verse = int(verse)\n",
    "    \n",
    "  return (True, (book, chapter, verse, head1, head2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pericopes = {}\n",
    "errors = {}\n",
    "\n",
    "sourceColumns = (\n",
    "  ('taksa', TAKSA, {}),\n",
    "  ('taksaTr', TAKSA_TR, {}),\n",
    "  ('siglum', SIGLUM, {}),\n",
    "  ('link', LINK, {}),\n",
    ")\n",
    "\n",
    "for (ln, line) in enumerate(lines):\n",
    "  if ln in skips:\n",
    "    continue\n",
    "  if test is not None and ln not in test:\n",
    "    continue\n",
    "  if line[VERSION_INDEX] != P_VAL:\n",
    "    continue\n",
    "    \n",
    "  for (name, index, dest) in sourceColumns:\n",
    "    dest[ln] = sanitize(line[index])\n",
    "  \n",
    "  pericopeStr = (simplify(line[P_INDEX], ln))\n",
    "  (good, data) = parsePericopes(pericopeStr, None)\n",
    "  if good:\n",
    "    pericopes[ln] = data\n",
    "  else:\n",
    "    errors[ln] = data\n",
    "  prevData = data[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  705 ?#?:?-? => #:\n",
      "\n",
      "    1 errors\n",
      " 8266 pericopes\n",
      "    0 Acts#08:05-13. => [[('Acts', 8, 5, None, None), ('Acts', 8, 13, None, None)]]\n",
      "\n",
      "    1 1Sm#16:01-13a. => [[('Sm1', 16, 1, None, None), ('Sm1', 16, 13, None, None)]]\n",
      "\n",
      "    2 Ct#01:02-14. => [[('Ct', 1, 2, None, None), ('Ct', 1, 14, None, None)]]\n",
      "\n",
      "    3 Jd#05:01-11. => [[('Jd', 5, 1, None, None), ('Jd', 5, 11, None, None)]]\n",
      "\n",
      "    4 Ex#03:01-10. => [[('Ex', 3, 1, None, None), ('Ex', 3, 10, None, None)]]\n",
      "\n",
      "    5 1Sm#01:09-19a.(‎‏ܠܪܡܬܐ‏‎) => [[('Sm1', 1, 9, None, None), ('Sm1', 1, 19, 'ܠܪܡܬܐ', None)]]\n",
      "\n",
      "    6 Nm#17:16-26. => [[('Nm', 17, 16, None, None), ('Nm', 17, 26, None, None)]]\n",
      "\n",
      "    7 Jd#13:02-14. => [[('Jd', 13, 2, None, None), ('Jd', 13, 14, None, None)]]\n",
      "\n",
      "    8 ‎2Cor#03:12-04:04. => [[('2Cor', 3, 12, None, None), ('2Cor', 4, 4, None, None)]]\n",
      "\n",
      "    9 Gn#12:07-08.+18:01-15. => [[('Gn', 12, 7, None, None), ('Gn', 12, 8, None, None)], [('Gn', 18, 1, None, None), ('Gn', 18, 15, None, None)]]\n",
      "\n",
      "   10 Gn#03:21-04:07. => [[('Gn', 3, 21, None, None), ('Gn', 4, 7, None, None)]]\n",
      "\n",
      "   11 Gn#17:01-09. => [[('Gn', 17, 1, None, None), ('Gn', 17, 9, None, None)]]\n",
      "\n",
      "   12 Pr#09:12-18. => [[('Pr', 9, 12, None, None), ('Pr', 9, 18, None, None)]]\n",
      "\n",
      "   13 Gn#05:01-24. => [[('Gn', 5, 1, None, None), ('Gn', 5, 24, None, None)]]\n",
      "\n",
      "   14 Is#02:11b(‎‏ܘܢܥܫܢ‏‎)-19. => [[('Is', 2, 11, 'ܘܢܥܫܢ', None), ('Is', 2, 19, None, None)]]\n",
      "\n",
      "   15 Gn#05:32-06:08. => [[('Gn', 5, 32, None, None), ('Gn', 6, 8, None, None)]]\n",
      "\n",
      "   16 Jl#02:15-03:05a. => [[('Jl', 2, 15, None, None), ('Jl', 3, 5, None, None)]]\n",
      "\n",
      "   17 Is#41:08-16. => [[('Is', 41, 8, None, None), ('Is', 41, 16, None, None)]]\n",
      "\n",
      "   18 Acts#18:19(‎‏ܘܥܠ‏‎)-19:20. => [[('Acts', 18, 19, 'ܘܥܠ', None), ('Acts', 19, 20, None, None)]]\n",
      "\n",
      "   19 Acts#13:13-23.+14:20(ܘܠܝܘܡܐ)-23. => [[('Acts', 13, 13, None, None), ('Acts', 13, 23, None, None)], [('Acts', 14, 20, 'ܘܠܝܘܡܐ', None), ('Acts', 14, 23, None, None)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if errors:\n",
    "  for (i, peri) in sorted(errors.items())[0:20]:\n",
    "    print(f'{i:>5} {raw[i]} => {peri}\\n')\n",
    "print(f'{len(errors):>5} errors')\n",
    "print(f'{len(pericopes):>5} pericopes')\n",
    "\n",
    "with open(ERROR_PATH, 'w') as f:\n",
    "  for (i, peri) in sorted(errors.items()):\n",
    "    f.write(f'{i:>5} {peri}\\n')\n",
    "    \n",
    "with open(PERI_PATH, 'w') as f:\n",
    "  for (i, peri) in sorted(pericopes.items()):\n",
    "    f.write(f'{i:>5} {peri}\\n')\n",
    "if pericopes:\n",
    "  for (i, peri) in sorted(pericopes.items())[0:20]:\n",
    "    print(f'{i:>5} {raw[i]} => {peri}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking\n",
    "\n",
    "### Resolving verse specifications and ranges\n",
    "\n",
    "First we define some functions that retrieve verse nodes for a range in a pericope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenVerses(volume, vStart, vEnd):\n",
    "  skipping = True\n",
    "  results = []\n",
    "  for vn in verseNodes[volume]:\n",
    "    if vn == vEnd:\n",
    "      break\n",
    "    if not skipping:\n",
    "      results.append(vn)\n",
    "    else:\n",
    "      if vn == vStart:\n",
    "        skipping = False\n",
    "  return tuple(results)\n",
    "  \n",
    "def versesFromSpec(spec):\n",
    "  (b, c, v) = spec[0:3]\n",
    "  (volume, bNode, bName) = bookInfo(b)\n",
    "  if bNode is None or volume is None:\n",
    "    return f'unknown book {b}'\n",
    "  if c is None:\n",
    "    return (volume, L[volume].d(bNode, otype='verse'))\n",
    "  elif v is None:\n",
    "    cNode = T[volume].nodeFromSection((bName, c))\n",
    "    if cNode is None:\n",
    "      return f'book {bName} has no chapter {c}'\n",
    "    return (volume, L[volume].d(cNode, otype='verse'))\n",
    "  else:\n",
    "    vNode = T[volume].nodeFromSection((bName, c, v))\n",
    "    if vNode is None:\n",
    "      return f'book {bName} has no verse {c}:{v}'\n",
    "    return (volume, (vNode,))\n",
    "\n",
    "def versesFromRange(rang):\n",
    "  if len(rang) == 1:\n",
    "    return versesFromSpec(rang[0])\n",
    "  (start, end) = rang\n",
    "  startResult = versesFromSpec(start)\n",
    "  if type(startResult) is str:\n",
    "    return f'start: {startResult}'\n",
    "  endResult = versesFromSpec(end)\n",
    "  if type(endResult) is str:\n",
    "    return f'end {endResult}'\n",
    "  (volume, startVerses) = startResult\n",
    "  (endVolume, endVerses) = endResult\n",
    "  if volume != endVolume:\n",
    "    return f'start in {volume} but end in {endVolume}: not supported'\n",
    "  lastStart = sortNodes[volume](startVerses)[-1]\n",
    "  firstEnd = sortNodes[volume](endVerses)[0]\n",
    "  sortedLF = sortNodes[volume]((lastStart, firstEnd))\n",
    "  if sortedLF != [lastStart, firstEnd]:\n",
    "    return (volume, [])\n",
    "  between = betweenVerses(volume, lastStart, firstEnd)\n",
    "  return (volume, startVerses + between + endVerses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "We want to test these functions.\n",
    "\n",
    "So we define a function to show a list of verse nodes, and then we call it on the results of a few test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showVerse(volume, verseNode):\n",
    "  if verseNode is None:\n",
    "    print('non existent verse')\n",
    "  else:\n",
    "    print('{} {}:{}'.format(*T[volume].sectionFromNode(verseNode)))\n",
    "  \n",
    "def showVerses(msg, spec, volume, verseNodes):\n",
    "  lV = len(verseNodes)\n",
    "  pl = '' if lV == 1 else 's'\n",
    "  print(f'{msg} {spec} => {volume}: {lV} verse{pl}')\n",
    "  if lV <= 3:\n",
    "    for vn in verseNodes:\n",
    "      showVerse(volume, vn)\n",
    "  else:\n",
    "    showVerse(volume, verseNodes[0])\n",
    "    print(' ... ')\n",
    "    showVerse(volume, verseNodes[-1])\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEC ('Gn', 1, 10) => peshitta: 1 verse\n",
      "Genesis 1:10\n",
      "\n",
      "SPEC ('Gn', 1, None) => peshitta: 31 verses\n",
      "Genesis 1:1\n",
      " ... \n",
      "Genesis 1:31\n",
      "\n",
      "SPEC ('Gn', None, None) => peshitta: 1533 verses\n",
      "Genesis 1:1\n",
      " ... \n",
      "Genesis 50:26\n",
      "\n",
      "SPEC ('Gn', 3, 25) => ERROR book Genesis has no verse 3:25\n",
      "SPEC ('Matt', 1, 10) => syrnt: 1 verse\n",
      "Matthew 1:10\n",
      "\n",
      "SPEC ('Matt', 1, None) => syrnt: 25 verses\n",
      "Matthew 1:1\n",
      " ... \n",
      "Matthew 1:25\n",
      "\n",
      "SPEC ('Matt', None, None) => syrnt: 1071 verses\n",
      "Matthew 1:1\n",
      " ... \n",
      "Matthew 28:20\n",
      "\n",
      "SPEC ('Acts', 8, 5, None, None) => syrnt: 1 verse\n",
      "Acts 8:5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for spec in (\n",
    "  ('Gn', 1, 10),\n",
    "  ('Gn', 1, None),\n",
    "  ('Gn', None, None),\n",
    "  ('Gn', 3, 25),\n",
    "  ('Matt', 1, 10),\n",
    "  ('Matt', 1, None),\n",
    "  ('Matt', None, None),\n",
    "  ('Acts', 8, 5, None, None),\n",
    "):\n",
    "  result = versesFromSpec(spec)\n",
    "  if type(result) is str:\n",
    "    print(f'SPEC {spec} => ERROR {result}')\n",
    "  else:\n",
    "    showVerses('SPEC', spec, *result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANGE (('Gn', 1, 1), ('Matt', 1, 1)) => ERROR start in peshitta but end in syrnt: not supported\n",
      "RANGE (('Gn', 1, 1),) => peshitta: 1 verse\n",
      "Genesis 1:1\n",
      "\n",
      "RANGE (('Gn', 1, 1), ('Gn', 1, 1)) => peshitta: 2 verses\n",
      "Genesis 1:1\n",
      "Genesis 1:1\n",
      "\n",
      "RANGE (('Gn', 1, 2), ('Gn', 1, 1)) => peshitta: 0 verses\n",
      "\n",
      "RANGE (('Gn', 1, 3), ('Gn', 1, 1)) => peshitta: 0 verses\n",
      "\n",
      "RANGE (('Gn', 1, 1), ('Gn', 1, 2)) => peshitta: 2 verses\n",
      "Genesis 1:1\n",
      "Genesis 1:2\n",
      "\n",
      "RANGE (('Gn', 1, 1), ('Gn', 1, 3)) => peshitta: 3 verses\n",
      "Genesis 1:1\n",
      "Genesis 1:2\n",
      "Genesis 1:3\n",
      "\n",
      "RANGE (('Gn', 1, 1), ('Gn', 1, 10)) => peshitta: 10 verses\n",
      "Genesis 1:1\n",
      " ... \n",
      "Genesis 1:10\n",
      "\n",
      "RANGE (('Gn', 1, None), ('Gn', 1, 10)) => peshitta: 0 verses\n",
      "\n",
      "RANGE (('Gn', 1, None), ('Gn', 2, 10)) => peshitta: 41 verses\n",
      "Genesis 1:1\n",
      " ... \n",
      "Genesis 2:10\n",
      "\n",
      "RANGE (('Gn', 1, None), ('Gn', 3, None)) => peshitta: 80 verses\n",
      "Genesis 1:1\n",
      " ... \n",
      "Genesis 3:24\n",
      "\n",
      "RANGE (('Gn', 40, 13), ('Ex', 3, 5)) => peshitta: 400 verses\n",
      "Genesis 40:13\n",
      " ... \n",
      "Exodus 3:5\n",
      "\n",
      "RANGE (('Gn', 3, 13), ('Gn', 3, 25)) => ERROR end book Genesis has no verse 3:25\n",
      "RANGE (('Acts', 8, 5, None, None), ('Acts', 8, 13, None, None)) => syrnt: 9 verses\n",
      "Acts 8:5\n",
      " ... \n",
      "Acts 8:13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rang in (\n",
    "  (('Gn', 1, 1), ('Matt', 1, 1)),\n",
    "  (('Gn', 1, 1),),\n",
    "  (('Gn', 1, 1), ('Gn', 1, 1)),\n",
    "  (('Gn', 1, 2), ('Gn', 1, 1)),\n",
    "  (('Gn', 1, 3), ('Gn', 1, 1)),\n",
    "  (('Gn', 1, 1), ('Gn', 1, 2)),\n",
    "  (('Gn', 1, 1), ('Gn', 1, 3)),\n",
    "  (('Gn', 1, 1), ('Gn', 1, 10)),\n",
    "  (('Gn', 1, None), ('Gn', 1, 10)),\n",
    "  (('Gn', 1, None), ('Gn', 2, 10)),\n",
    "  (('Gn', 1, None), ('Gn', 3, None)),\n",
    "  (('Gn', 40, 13), ('Ex', 3, 5)),\n",
    "  (('Gn', 3, 13), ('Gn', 3, 25)),\n",
    "  (('Acts', 8, 5, None, None), ('Acts', 8, 13, None, None)),\n",
    "):\n",
    "  result = versesFromRange(rang)\n",
    "  if type(result) is str:\n",
    "    print(f'RANGE {rang} => ERROR {result}')\n",
    "  else:\n",
    "    showVerses('RANGE', rang, *result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature construction\n",
    "\n",
    "Make a feature `lectio`, for verse nodes, which is 1 for verses mentioned in a pericope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "rangeErrors = []\n",
    "lectio = {}\n",
    "mark1 = {}\n",
    "mark2 = {}\n",
    "extra = {}\n",
    "for (name, index, source) in sourceColumns:\n",
    "  extra[name] = {}\n",
    "\n",
    "for volume in A:\n",
    "  lectio[volume] = {}\n",
    "  mark1[volume] = {}\n",
    "  mark2[volume] = {}\n",
    "  for name in extra:\n",
    "    extra[name][volume] = collections.defaultdict(set)\n",
    "\n",
    "for (ln, ranges) in pericopes.items():\n",
    "  for rang in ranges:\n",
    "    result = versesFromRange(rang)\n",
    "    if type(result) is str:\n",
    "      rangeErrors.append((ln, result))\n",
    "    else:\n",
    "      (volume, vns) = result\n",
    "      for vn in vns:\n",
    "        old = lectio[volume].setdefault(vn, '')\n",
    "        sep = ',' if old else ''\n",
    "        lectio[volume][vn] = f'{old}{sep}{str(ln)}'\n",
    "        for (name, index, source) in sourceColumns:\n",
    "          val = source[ln]\n",
    "          if val:\n",
    "            extra[name][volume][vn].add(source[ln])\n",
    "        \n",
    "    for spec in rang:\n",
    "      result = versesFromSpec(spec)\n",
    "      if type(result) is str:\n",
    "        continue\n",
    "      else:\n",
    "        (volume, vns) = result\n",
    "        for (i, m) in enumerate(spec[3:5]):\n",
    "          if m is not None:\n",
    "            for vn in vns:\n",
    "              dest = mark1 if i == 0 else mark2\n",
    "              old = dest[volume].setdefault(vn, '')\n",
    "              sep = '|' if old else ''\n",
    "              dest[volume][vn] = f'{old}{sep}{str(ln)}:{m}'\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the extra features are sets.\n",
    "We convert them to strings, by joining the sorted elements by `|`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, nameData) in extra.items():\n",
    "  for (volume, volumeData) in nameData.items():\n",
    "    for (vn, valSet) in volumeData.items():\n",
    "      volumeData[vn] = '|'.join(sorted(valSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks:\n",
    "\n",
    "* range errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 errors\n",
      "  492 book Numbers has no verse 9:26\n",
      "  619 start: book Kings_1 has no verse 17:30\n",
      "  734 end book Exodus has no verse 3:28\n",
      "  768 end book Numbers has no verse 12:28\n",
      "  861 book 2_Thessalonians has no verse 4:13\n",
      " 1213 start: book Judges has no verse 30:34\n",
      " 1263 book 1_Thessalonians has no verse 1:25\n",
      " 3914 end book 1_Corinthians has no verse 5:16\n",
      " 3914 start: book 1_Corinthians has no verse 5:17\n",
      " 4042 end book Proverbs has no verse 13:23\n",
      " 4243 start: book Isaiah has no verse 54:41\n",
      " 4244 start: book Isaiah has no verse 54:171\n",
      " 5178 end book 2_Corinthians has no verse 4:21\n",
      " 5214 start: book Acts has no verse 1:33\n",
      " 5217 end book Ezekiel has no verse 9:15\n",
      " 5563 start: book Exodus has no verse 15:1311\n",
      " 5984 book Exodus has no verse 43:51\n",
      " 6314 end book Ezekiel has no verse 9:15\n",
      " 6420 end book Acts has no verse 31:7\n",
      " 6543 end book Romans has no verse 16:28\n",
      "\n",
      "Annotated verses:\n",
      "peshitta: 11370 verses\n",
      "syrnt: 4696 verses\n"
     ]
    }
   ],
   "source": [
    "if rangeErrors:\n",
    "  print(f'{len(rangeErrors)} errors')\n",
    "  for (ln, e) in rangeErrors[0:20]:\n",
    "    print(f'{ln:>5} {e}')\n",
    "else:\n",
    "  print('No range errors')\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Annotated verses:')\n",
    "for volume in lectio:\n",
    "  print(f'{volume}: {len(lectio[volume])} verses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save lectio as TF\n",
    "\n",
    "First we specify some metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = {\n",
    "  P: 'lectionary data for the Peshitta (OT)',\n",
    "  S: 'lectionary data for the Peshitta (NT)',\n",
    "}\n",
    "metaDataBase = {\n",
    "  '' : {\n",
    "    'editor': 'Geert Jan Veldman',\n",
    "    'converter': 'Dirk Roorda',\n",
    "  },\n",
    "  'lectio': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'numbers of lectionaries associated to verses (comma separated)'\n",
    "  },\n",
    "  'mark1': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'lectionary start mark associated to verses (| separated ln:mark values)'\n",
    "  },\n",
    "  'mark2': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'lectionary start mark (alternative language) associated to verses (| separated ln:mark values)'\n",
    "  },\n",
    "  'taksa': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'taksa of lectionaries associated to verses (comma separated)'\n",
    "  },\n",
    "  'taksaTr': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'taksa (translation) of lectionaries associated to verses (comma separated)'\n",
    "  },\n",
    "  'siglum': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'siglum of lectionaries associated to verses (comma separated)'\n",
    "  },\n",
    "  'link': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'archive link to manuscript of lectionaries associated to verses (comma separated)'\n",
    "  },\n",
    "}\n",
    "\n",
    "metaData = {}\n",
    "\n",
    "for volume in dataName:\n",
    "  meta = {}\n",
    "  meta.update(metaDataBase)\n",
    "  meta['']['name'] = dataName[volume]\n",
    "  metaData[volume] = meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we make the features ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeFeatures = {}\n",
    "\n",
    "collectedData = [\n",
    "  ('lectio', lectio),\n",
    "  ('mark1', mark1),\n",
    "  ('mark2', mark2),\n",
    "]\n",
    "for (name, data) in extra.items():\n",
    "  collectedData.append((name, data))\n",
    "  \n",
    "for (name, data) in collectedData:\n",
    "  for volume in data:\n",
    "    nodeFeatures.setdefault(volume, {})[name] = data[volume]\n",
    "  \n",
    "edgeFeatures = {\n",
    "  P: {},\n",
    "  S: {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Exporting 7 node and 0 edge and 0 config features to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1:\n",
      "   |     0.02s T lectio               to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1\n",
      "   |     0.02s T link                 to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1\n",
      "   |     0.00s T mark1                to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1\n",
      "   |     0.00s T mark2                to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1\n",
      "   |     0.02s T siglum               to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1\n",
      "   |     0.04s T taksa                to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1\n",
      "   |     0.04s T taksaTr              to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1\n",
      "  0.15s Exported 7 node features and 0 edge features and 0 config features to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/peshitta/0.1\n",
      "  0.00s Exporting 7 node and 0 edge and 0 config features to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1:\n",
      "   |     0.01s T lectio               to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1\n",
      "   |     0.00s T link                 to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1\n",
      "   |     0.00s T mark1                to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1\n",
      "   |     0.00s T mark2                to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1\n",
      "   |     0.01s T siglum               to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1\n",
      "   |     0.01s T taksa                to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1\n",
      "   |     0.01s T taksaTr              to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1\n",
      "  0.05s Exported 7 node features and 0 edge features and 0 config features to /Users/dirk/github/etcbc/linksyr/data/tf/lectio/syrnt/0.1\n"
     ]
    }
   ],
   "source": [
    "for volume in lectio:\n",
    "  if os.path.exists(tfDir[volume]):\n",
    "    rmtree(tfDir[volume])\n",
    "  os.makedirs(tfDir[volume], exist_ok=True)\n",
    "  TF[volume].save(nodeFeatures=nodeFeatures[volume], edgeFeatures=edgeFeatures[volume], metaData=metaData[volume])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

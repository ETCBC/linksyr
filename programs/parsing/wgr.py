from __future__ import print_function
import sys, re
# from yapps import runtime
import yapps_runtime as runtime

# give distinctive values to some useful keywords
mc_inflection, mc_derivation = range(2)
prefix, core, infix, suffix, pattern = range(5)
left, right = range(2)


# Begin -- grammar generated by Yapps

class wgrScanner(runtime.Scanner):
    patterns = [
        ("'\\\\)'", re.compile('\\)')),
        ("'\\\\('", re.compile('\\(')),
        ("'\\+'", re.compile('\\+')),
        ("'-'", re.compile('-')),
        ("'}'", re.compile('}')),
        ("'{'", re.compile('{')),
        ("':'", re.compile(':')),
        ("'<'", re.compile('<')),
        ("','", re.compile(',')),
        ("'='", re.compile('=')),
        ('\\s+', re.compile('\\s+')),
        ('#[^\\n]*', re.compile('#[^\\n]*')),
        ('T_ACCEPT', re.compile('accept')),
        ('T_CORE', re.compile('core')),
        ('T_DERIVATION', re.compile('derivation')),
        ('T_END', re.compile('end')),
        ('T_EXIST', re.compile('exist')),
        ('T_FORMS', re.compile('forms')),
        ('T_FUNCTIONS', re.compile('functions')),
        ('T_GOTO', re.compile('goto')),
        ('T_INFIX', re.compile('infix')),
        ('T_INFLECTION', re.compile('inflection')),
        ('T_LABEL', re.compile('label')),
        ('T_LEXICAL', re.compile('lexical')),
        ('T_META', re.compile('meta')),
        ('T_NOT', re.compile('not')),
        ('T_PATTERN', re.compile('pattern')),
        ('T_PREFIX', re.compile('prefix')),
        ('T_REJECT', re.compile('reject')),
        ('T_RULES', re.compile('rules')),
        ('T_SHARED', re.compile('shared')),
        ('T_SUFFIX', re.compile('suffix')),
        ('T_WORD', re.compile('word')),
        ('T_ACTION_OPERATOR', re.compile('::')),
        ('T_AND', re.compile('&&')),
        ('T_CHARACTER', re.compile('.')),
        ('T_COMMENT', re.compile('#.*')),
        ('T_EQUALITY', re.compile('==')),
        ('T_IDENTIFIER', re.compile('[A-Za-z_][A-Za-z0-9_]*')),
        ('T_INEQUALITY', re.compile('!=')),
        ('T_STRING', re.compile('"[^"]*"')),
        ('T_LWSP', re.compile('[\\t\\v\\f\\r ]+')),
        ('T_OR', re.compile('\\|\\|')),
        ('END', re.compile('$')),
    ]
    def __init__(self, str,*args,**kw):
        runtime.Scanner.__init__(self,None,{'\\s+':None,'#[^\\n]*':None,},str,*args,**kw)

class wgr(runtime.Parser):
    Context = runtime.Context
    def grammar(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'grammar', [])
        word = self.word(_context)
        forms = self.forms(_context)
        functions = self.functions(_context)
        rules = self.rules(_context)
        END = self._scan('END', context=_context)
        return W

    def word(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'word', [])
        T_WORD = self._scan('T_WORD', context=_context)
        W.reset()
        word_inflection = self.word_inflection(_context)
        word_derivation = self.word_derivation(_context)

    def forms(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'forms', [])
        T_FORMS = self._scan('T_FORMS', context=_context)
        metasymbols = self.metasymbols(_context)
        while self._peek('T_FUNCTIONS', 'T_IDENTIFIER', context=_context) == 'T_IDENTIFIER':
            forms_declaration = self.forms_declaration(_context)

    def functions(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'functions', [])
        T_FUNCTIONS = self._scan('T_FUNCTIONS', context=_context)
        while self._peek('T_RULES', 'T_IDENTIFIER', context=_context) == 'T_IDENTIFIER':
            function_declaration = self.function_declaration(_context)

    def rules(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'rules', [])
        T_RULES = self._scan('T_RULES', context=_context)
        rules_inflection = self.rules_inflection(_context)
        rules_derivation = self.rules_derivation(_context)

    def word_inflection(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'word_inflection', [])
        T_INFLECTION = self._scan('T_INFLECTION', context=_context)
        W.setmclass(mc_inflection)
        prefix = self.prefix(_context)
        core = self.core(_context)
        infix = self.infix(_context)
        suffix = self.suffix(_context)
        pattern = self.pattern(_context)

    def word_derivation(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'word_derivation', [])
        T_DERIVATION = self._scan('T_DERIVATION', context=_context)
        W.setmclass(mc_derivation)
        prefix = self.prefix(_context)
        core = self.core(_context)
        infix = self.infix(_context)
        suffix = self.suffix(_context)
        pattern = self.pattern(_context)

    def metasymbols(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'metasymbols', [])
        T_META = self._scan('T_META', context=_context)
        metas = []
        string = self.string(_context)
        metas.append(string[1])
        string = self.string(_context)
        metas.append(string[1])
        string = self.string(_context)
        metas.append(string[1])
        string = self.string(_context)
        metas.append(string[1])
        W.setmetas(metas)

    def forms_declaration(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'forms_declaration', [])
        identifier = self.identifier(_context)
        forms_enumeration = self.forms_enumeration(identifier[1], _context)

    def function_declaration(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'function_declaration', [])
        wf_declaration = self.wf_declaration(_context)
        self._scan("'='", context=_context)
        fvenum = set()
        fv_declaration = self.fv_declaration(_context)
        fvenum.add(fv_declaration)
        while self._peek("','", 'T_IDENTIFIER', 'T_RULES', context=_context) == "','":
            self._scan("','", context=_context)
            fv_declaration = self.fv_declaration(_context)
            fvenum.add(fv_declaration)
        W.addfvenum(wf_declaration, fvenum)

    def rules_inflection(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'rules_inflection', [])
        T_INFLECTION = self._scan('T_INFLECTION', context=_context)
        W.setmclass(mc_inflection)
        while self._peek('T_LABEL', 'T_DERIVATION', 'END', 'T_SHARED', 'T_NOT', "'\\\\('", 'T_IDENTIFIER', 'T_EXIST', context=_context) not in ['T_DERIVATION', 'END']:
            rule_ = self.rule_(_context)
            W.addrule(rule_)
        pass

    def rules_derivation(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'rules_derivation', [])
        _token = self._peek('T_DERIVATION', 'END', context=_context)
        if _token == 'END':
            pass
        else: # == 'T_DERIVATION'
            T_DERIVATION = self._scan('T_DERIVATION', context=_context)
            W.setmclass(mc_derivation)
            while self._peek('T_LABEL', 'END', 'T_SHARED', 'T_NOT', "'\\\\('", 'T_IDENTIFIER', 'T_EXIST', context=_context) != 'END':
                rule_ = self.rule_(_context)
                W.addrule(rule_)
            pass

    def prefix(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'prefix', [])
        _token = self._peek('T_PREFIX', 'T_CORE', context=_context)
        if _token == 'T_CORE':
            pass
        else: # == 'T_PREFIX'
            T_PREFIX = self._scan('T_PREFIX', context=_context)
            self._scan("'='", context=_context)
            while self._peek('T_IDENTIFIER', 'T_INFIX', 'T_CORE', 'T_SUFFIX', 'T_PATTERN', 'T_DERIVATION', 'T_FORMS', context=_context) == 'T_IDENTIFIER':
                mt_declaration = self.mt_declaration(prefix, _context)
            pass

    def core(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'core', [])
        T_CORE = self._scan('T_CORE', context=_context)
        self._scan("'='", context=_context)
        mt_declaration = self.mt_declaration(core, _context)

    def infix(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'infix', [])
        _token = self._peek('T_INFIX', 'T_SUFFIX', 'T_PATTERN', 'T_DERIVATION', 'T_FORMS', context=_context)
        if _token != 'T_INFIX':
            pass
        else: # == 'T_INFIX'
            T_INFIX = self._scan('T_INFIX', context=_context)
            self._scan("'='", context=_context)
            while self._peek('T_IDENTIFIER', 'T_INFIX', 'T_SUFFIX', 'T_PATTERN', 'T_CORE', 'T_DERIVATION', 'T_FORMS', context=_context) == 'T_IDENTIFIER':
                mt_declaration = self.mt_declaration(infix, _context)
            pass

    def suffix(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'suffix', [])
        _token = self._peek('T_SUFFIX', 'T_PATTERN', 'T_DERIVATION', 'T_FORMS', context=_context)
        if _token != 'T_SUFFIX':
            pass
        else: # == 'T_SUFFIX'
            T_SUFFIX = self._scan('T_SUFFIX', context=_context)
            self._scan("'='", context=_context)
            while self._peek('T_IDENTIFIER', 'T_INFIX', 'T_SUFFIX', 'T_PATTERN', 'T_CORE', 'T_DERIVATION', 'T_FORMS', context=_context) == 'T_IDENTIFIER':
                mt_declaration = self.mt_declaration(suffix, _context)
            pass

    def pattern(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'pattern', [])
        _token = self._peek('T_PATTERN', 'T_DERIVATION', 'T_FORMS', context=_context)
        if _token != 'T_PATTERN':
            pass
        else: # == 'T_PATTERN'
            T_PATTERN = self._scan('T_PATTERN', context=_context)
            self._scan("'='", context=_context)
            while self._peek('T_IDENTIFIER', 'T_INFIX', 'T_SUFFIX', 'T_PATTERN', 'T_DERIVATION', 'T_CORE', 'T_FORMS', context=_context) == 'T_IDENTIFIER':
                mt_declaration = self.mt_declaration(pattern, _context)
            pass

    def forms_enumeration(self, mtid, _parent=None):
        _context = self.Context(_parent, self._scanner, 'forms_enumeration', [mtid])
        _token = self._peek("'='", "'<'", context=_context)
        if _token == "'='":
            explicit_enum = self.explicit_enum(mtid, _context)
        else: # == "'<'"
            implicit_enum = self.implicit_enum(mtid, _context)

    def explicit_enum(self, mtid, _parent=None):
        _context = self.Context(_parent, self._scanner, 'explicit_enum', [mtid])
        mvenum = set()
        self._scan("'='", context=_context)
        mv_declaration = self.mv_declaration(_context)
        mvenum.add(mv_declaration)
        while self._peek("','", 'T_IDENTIFIER', 'T_FUNCTIONS', context=_context) == "','":
            self._scan("','", context=_context)
            mv_declaration = self.mv_declaration(_context)
            mvenum.add(mv_declaration)
        W.addmvenum(mtid, mvenum)

    def implicit_enum(self, mtid, _parent=None):
        _context = self.Context(_parent, self._scanner, 'implicit_enum', [mtid])
        self._scan("'<'", context=_context)
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        W.addmvenum(mtid, getattr(W, T_IDENTIFIER))

    def mv_declaration(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'mv_declaration', [])
        _token = self._peek('T_IDENTIFIER', 'T_STRING', context=_context)
        if _token == 'T_IDENTIFIER':
            T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
            return T_IDENTIFIER
        else: # == 'T_STRING'
            string = self.string(_context)
            return string[1]

    def wf_declaration(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'wf_declaration', [])
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        self._scan("':'", context=_context)
        string = self.string(_context)
        W.addwf(T_IDENTIFIER, string[1])
        return T_IDENTIFIER

    def fv_declaration(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'fv_declaration', [])
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        self._scan("':'", context=_context)
        string = self.string(_context)
        W.addfv(T_IDENTIFIER, string[1])
        return T_IDENTIFIER

    def mt_declaration(self, p, _parent=None):
        _context = self.Context(_parent, self._scanner, 'mt_declaration', [p])
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        self._scan("':'", context=_context)
        marker_set = self.marker_set(p, _context)
        string = self.string(_context)
        W.addmt(T_IDENTIFIER, p, marker_set, string[1])

    def rule_(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'rule_', [])
        label = self.label(_context)
        rule_definition = self.rule_definition(_context)
        return ('label', (label, rule_definition)) if label else rule_definition

    def label(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'label', [])
        _token = self._peek('T_LABEL', 'T_SHARED', 'T_NOT', "'\\\\('", 'T_IDENTIFIER', 'T_EXIST', context=_context)
        if _token != 'T_LABEL':
            pass
        else: # == 'T_LABEL'
            T_LABEL = self._scan('T_LABEL', context=_context)
            T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
            return T_IDENTIFIER

    def rule_definition(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'rule_definition', [])
        _token = self._peek('T_SHARED', 'T_NOT', "'\\\\('", 'T_IDENTIFIER', 'T_EXIST', context=_context)
        if _token != 'T_SHARED':
            simple_rule = self.simple_rule(_context)
            return ('simple_rule', simple_rule)
        else: # == 'T_SHARED'
            block = self.block(_context)
            return ('block', block)

    def marker_set(self, p, _parent=None):
        _context = self.Context(_parent, self._scanner, 'marker_set', [p])
        self._scan("'{'", context=_context)
        m = [None, None]
        if self._peek("'}'", 'T_STRING', context=_context) == 'T_STRING':
            string = self.string(_context)
            m[left] = string[1]
            if self._peek("','", "'}'", context=_context) == "','":
                self._scan("','", context=_context)
                string = self.string(_context)
                m[right] = string[1]
        self._scan("'}'", context=_context)
        if (m[right] is None and p == prefix): m.reverse()
        return m

    def simple_rule(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'simple_rule', [])
        expression = self.expression(_context)
        T_ACTION_OPERATOR = self._scan('T_ACTION_OPERATOR', context=_context)
        actions = []
        action = self.action(_context)
        actions.append(action)
        while self._peek("','", 'T_END', 'T_LABEL', 'T_SHARED', 'T_DERIVATION', 'END', 'T_NOT', "'\\\\('", 'T_IDENTIFIER', 'T_EXIST', context=_context) == "','":
            self._scan("','", context=_context)
            action = self.action(_context)
            actions.append(action)
        return (expression, actions)

    def block(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'block', [])
        shared_rule = self.shared_rule(_context)
        rules = []
        while 1:
            rule_ = self.rule_(_context)
            rules.append(rule_)
            if self._peek('T_LABEL', 'T_SHARED', 'T_NOT', "'\\\\('", 'T_IDENTIFIER', 'T_EXIST', 'T_END', context=_context) not in ['T_LABEL', 'T_SHARED', 'T_NOT', "'\\\\('", 'T_IDENTIFIER', 'T_EXIST']: break
        T_END = self._scan('T_END', context=_context)
        return (shared_rule, rules)

    def shared_rule(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'shared_rule', [])
        T_SHARED = self._scan('T_SHARED', context=_context)
        self._scan("'{'", context=_context)
        expression = self.expression(_context)
        shared_actions = self.shared_actions(_context)
        self._scan("'}'", context=_context)
        return (expression, shared_actions)

    def expression(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'expression', [])
        e = []
        term = self.term(_context)
        e.append(term)
        while self._peek('T_OR', 'T_ACTION_OPERATOR', "'\\\\)'", "'}'", context=_context) == 'T_OR':
            T_OR = self._scan('T_OR', context=_context)
            term = self.term(_context)
            e.append(term)
        return e[0] if len(e) == 1 else ('or', tuple(e))

    def shared_actions(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'shared_actions', [])
        _token = self._peek('T_ACTION_OPERATOR', "'}'", context=_context)
        if _token == "'}'":
            pass
        else: # == 'T_ACTION_OPERATOR'
            T_ACTION_OPERATOR = self._scan('T_ACTION_OPERATOR', context=_context)
            a = []
            action = self.action(_context)
            a.append(action)
            while self._peek("','", "'}'", context=_context) == "','":
                self._scan("','", context=_context)
                action = self.action(_context)
                a.append(action)
            return a

    def action(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'action', [])
        _token = self._peek('T_ACCEPT', 'T_REJECT', 'T_IDENTIFIER', "'-'", "'\\+'", 'T_GOTO', context=_context)
        if _token not in ['T_ACCEPT', 'T_REJECT', 'T_GOTO']:
            attribution = self.attribution(_context)
            return attribution
        else: # in ['T_ACCEPT', 'T_REJECT', 'T_GOTO']
            shift = self.shift(_context)
            return shift

    def attribution(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'attribution', [])
        _token = self._peek('T_IDENTIFIER', "'-'", "'\\+'", context=_context)
        if _token == 'T_IDENTIFIER':
            assignment = self.assignment(_context)
            return ('assignment', assignment)
        elif _token == "'-'":
            exclusion = self.exclusion(_context)
            return ('exclusion', exclusion)
        else: # == "'\\+'"
            inclusion = self.inclusion(_context)
            return ('inclusion', inclusion)

    def shift(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'shift', [])
        _token = self._peek('T_ACCEPT', 'T_REJECT', 'T_GOTO', context=_context)
        if _token == 'T_GOTO':
            jump = self.jump(_context)
            return ('jump', jump)
        elif _token == 'T_ACCEPT':
            T_ACCEPT = self._scan('T_ACCEPT', context=_context)
            return ('accept', T_ACCEPT)
        else: # == 'T_REJECT'
            T_REJECT = self._scan('T_REJECT', context=_context)
            return ('reject', T_REJECT )

    def assignment(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'assignment', [])
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        f = T_IDENTIFIER
        self._scan("'='", context=_context)
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        return (f, T_IDENTIFIER)

    def jump(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'jump', [])
        T_GOTO = self._scan('T_GOTO', context=_context)
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        return T_IDENTIFIER

    def exclusion(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'exclusion', [])
        self._scan("'-'", context=_context)
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        return T_IDENTIFIER

    def inclusion(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'inclusion', [])
        self._scan("'\\+'", context=_context)
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        return T_IDENTIFIER

    def term(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'term', [])
        t = []
        factor = self.factor(_context)
        t.append(factor)
        while self._peek('T_AND', 'T_OR', 'T_ACTION_OPERATOR', "'\\\\)'", "'}'", context=_context) == 'T_AND':
            T_AND = self._scan('T_AND', context=_context)
            factor = self.factor(_context)
            t.append(factor)
        return t[0] if len(t) == 1 else ('and', tuple(t))

    def factor(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'factor', [])
        _token = self._peek('T_NOT', "'\\\\('", 'T_IDENTIFIER', 'T_EXIST', context=_context)
        if _token not in ['T_NOT', "'\\\\('"]:
            simple_factor = self.simple_factor(_context)
            return simple_factor
        elif _token == 'T_NOT':
            negated_factor = self.negated_factor(_context)
            return negated_factor
        else: # == "'\\\\('"
            grouped_factor = self.grouped_factor(_context)
            return grouped_factor

    def simple_factor(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'simple_factor', [])
        _token = self._peek('T_IDENTIFIER', 'T_EXIST', context=_context)
        if _token == 'T_IDENTIFIER':
            comparison = self.comparison(_context)
            return comparison
        else: # == 'T_EXIST'
            existence = self.existence(_context)
            return existence

    def negated_factor(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'negated_factor', [])
        T_NOT = self._scan('T_NOT', context=_context)
        factor = self.factor(_context)
        return ('not', factor)

    def grouped_factor(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'grouped_factor', [])
        self._scan("'\\\\('", context=_context)
        expression = self.expression(_context)
        self._scan("'\\\\)'", context=_context)
        return expression

    def comparison(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'comparison', [])
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        relational_operator = self.relational_operator(_context)
        value = self.value(_context)
        c = (T_IDENTIFIER, value, relational_operator)
        return ('cmp', c)

    def existence(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'existence', [])
        T_EXIST = self._scan('T_EXIST', context=_context)
        self._scan("'\\\\('", context=_context)
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        self._scan("'\\\\)'", context=_context)
        return ('exist', T_IDENTIFIER)

    def relational_operator(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'relational_operator', [])
        _token = self._peek('T_EQUALITY', 'T_INEQUALITY', context=_context)
        if _token == 'T_EQUALITY':
            T_EQUALITY = self._scan('T_EQUALITY', context=_context)
            return True
        else: # == 'T_INEQUALITY'
            T_INEQUALITY = self._scan('T_INEQUALITY', context=_context)
            return False

    def value(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'value', [])
        _token = self._peek("'{'", 'T_IDENTIFIER', 'T_STRING', context=_context)
        if _token != "'{'":
            single_value = self.single_value(_context)
            return set([single_value])
        else: # == "'{'"
            value_set = self.value_set(_context)
            return value_set

    def single_value(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'single_value', [])
        _token = self._peek('T_IDENTIFIER', 'T_STRING', context=_context)
        if _token == 'T_IDENTIFIER':
            identifier = self.identifier(_context)
            return identifier[1]
        else: # == 'T_STRING'
            string = self.string(_context)
            return string[1]

    def value_set(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'value_set', [])
        self._scan("'{'", context=_context)
        vset = set()
        single_value = self.single_value(_context)
        vset.add(single_value)
        while self._peek("'}'", "','", context=_context) == "','":
            self._scan("','", context=_context)
            single_value = self.single_value(_context)
            vset.add(single_value)
        self._scan("'}'", context=_context)
        return vset

    def string(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'string', [])
        T_STRING = self._scan('T_STRING', context=_context)
        return ('str', T_STRING[1:-1])

    def identifier(self, _parent=None):
        _context = self.Context(_parent, self._scanner, 'identifier', [])
        T_IDENTIFIER = self._scan('T_IDENTIFIER', context=_context)
        return ('ident', T_IDENTIFIER)


def parse(rule, text):
    P = wgr(wgrScanner(text))
    return runtime.wrap_error_reporter(P, rule)

# End -- grammar generated by Yapps


if __name__ == '__main__':
    from sys import argv, stdin
    if len(argv) >= 2:
        if len(argv) >= 3:
            f = open(argv[2],'r')
        else:
            f = stdin
        print(parse(argv[1], f.read()))
    else: print ('Args:  <rule> [<filename>]', file=sys.stderr)

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Een parser-generator voor de wordgrammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De parser-generator voor de ETCBC-wordgrammar-bestanden is gegenereerd met Yapps2 (zie de website: http://theory.stanford.edu/~amitp/yapps/ en https://github.com/smurfix/yapps) met het grammar-bestand `wgr.g`, wat resulteert in de grammar-parser `wgr.py`. Dat script is afhankelijk van de runtime-module van Yapps, hier meegeleverd als het bestand `yapps-runtime.py`.\n",
    "\n",
    "Wat we eigenlijk willen is niet het parsen van de `wordgrammar`-bestanden, wat `wgr.py` doet, maar het parsen van de morphologische analyse van de ETCBC-database. Dat gebeurt in `wrdgrm.py`. Dat is, behalve van `wgr.py` en `yapps-runtime.py`, nog afhankelijk van de modules `alphabet.py` en `lexicon.py` (**TODO**: dat moet makkelijker kunnen). Tenslotte zijn de databestanden vereist: het alfabet, het lexicon en de wordgrammar zelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eerst modules importeren\n",
    "import os, wrdgrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = lambda rel_path: os.path.realpath(os.path.join(os.getcwd(), rel_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestandslocaties\n",
    "alphabet_file = filepath('../../data/wordgrammar/alphabet')\n",
    "lexicon_file = filepath('../../data/blc/syrlex')\n",
    "word_grammar_file = filepath('../../data/blc/syrwgr')\n",
    "an_file = filepath('../../data/blc/Laws.an')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dan kan de parser worden geïnitialiseerd\n",
    "w = wrdgrm.wrdgrm(word_grammar_file, lexicon_file, alphabet_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De functie `analyze_word()` geeft een analyse als een tuple met drie waarden: `morphemes`, `functions` en `lex`.\n",
    "\n",
    "De eerste, `morphemes`, bevat een tuple met alle gevonden morfemen, elk als een tuple met drie strings: de paradigmatische vorm (zoals die in het lexicon staat), de oppervlaktevorm (zoals die in de tekst staat), en de geannoteerde vorm met morfologische codering.\n",
    "\n",
    "De tweede waarde, `functions`, bevat de grammaticale functies van het woord, zoals die in de `wordgrammar` gedefinieerd zijn: `ps: \"person\"`, `nu: \"number\"`, `gn: \"gender\"`, `ls: \"lexical set\"`, `sp: \"part of speech\"`, `st: \"state\"`, `vo: \"voice\"`, `vs: \"verbal stem\"`, `vt: \"verbal tense\"`. Een veld met de waarde `False` geeft aan dat deze functie niet van toepassing is op dit woord, een veld met waarde `None` geeft aan dat de waarde niet is vastgesteld.\n",
    "\n",
    "De derde waarde, `lex`, bevat het lemma zoals dat in het lexicon staat, met als eerste het woord-id, en vervolgens de annotaties. Behalve standaard-waarden voor de grammaticale functies bevat het lexicon een `gl`-veld voor ieder woord (gloss), en soms een `de`-veld (derived form). (In één resp. twee gevallen komen ook de velden `cs` en `ln` voor, waarvan de betekenis mij niet duidelijk is.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('lex', ('>TR', '>TR', '>TR')),\n",
       "  ('nme', ('T=', 'WT', '&WT=')),\n",
       "  ('emf', ('>', '>', '>'))),\n",
       " (('vt', False),\n",
       "  ('vs', False),\n",
       "  ('ps', False),\n",
       "  ('sp', 'subs'),\n",
       "  ('nu', 'pl'),\n",
       "  ('gn', 'm'),\n",
       "  ('st', 'emph')),\n",
       " ('17789', (('sp', 'subs'), ('gn', 'm'), ('gl', 'place, region'))))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voorbeeld\n",
    "w.analyze_word('>TR/&WT=~>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1 TWB TWB\n",
      "\t(('lex', ('TWB', 'TWB', 'TWB')),)\n",
      "\t(('nu', False), ('gn', False), ('st', False), ('vt', False), ('vs', False), ('ps', False), ('sp', 'advb'))\n",
      "\t('11299', (('sp', 'advb'), ('gl', 'again, back')))\n",
      "0,1 KTB> KTB=/~>\n",
      "\t(('lex', ('KTB=', 'KTB', 'KTB=')), ('nme', ('', '', '')), ('emf', ('>', '>', '>')))\n",
      "\t(('vt', False), ('vs', False), ('ps', False), ('sp', 'subs'), ('nu', None), ('gn', 'm'), ('st', 'emph'))\n",
      "\t('8929', (('sp', 'subs'), ('gn', 'm'), ('gl', 'writing, book')))\n",
      "0,1 DNM\"WS> D-NMWS/(J~>\n",
      "\t(('lex', ('D', 'D', 'D')),)\n",
      "\t(('nu', False), ('gn', False), ('st', False), ('vt', False), ('vs', False), ('ps', False), ('sp', 'prep'), ('ls', 'pcon'))\n",
      "\t('7789', (('sp', 'prep'), ('ls', 'pcon'), ('gl', '(relative)')))\n",
      "\t(('lex', ('NMWS', 'NMWS', 'NMWS')), ('nme', ('J', '', '(J')), ('emf', ('>', '>', '>')))\n",
      "\t(('vt', False), ('vs', False), ('ps', False), ('sp', 'subs'), ('nu', 'pl'), ('gn', 'm'), ('st', 'emph'))\n",
      "\t('2063', (('sp', 'subs'), ('gn', 'm'), ('gl', 'nome, prefecture, law, custom, usage')))\n",
      "0,1 D>TR\"WT> D->TR/&WT=~>\n",
      "\t(('lex', ('D', 'D', 'D')),)\n",
      "\t(('nu', False), ('gn', False), ('st', False), ('vt', False), ('vs', False), ('ps', False), ('sp', 'prep'), ('ls', 'pcon'))\n",
      "\t('7789', (('sp', 'prep'), ('ls', 'pcon'), ('gl', '(relative)')))\n",
      "\t(('lex', ('>TR', '>TR', '>TR')), ('nme', ('T=', 'WT', '&WT=')), ('emf', ('>', '>', '>')))\n",
      "\t(('vt', False), ('vs', False), ('ps', False), ('sp', 'subs'), ('nu', 'pl'), ('gn', 'm'), ('st', 'emph'))\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# toon alle beschikbare data uit de an-file:\n",
    "def print_anfile(an_file):\n",
    "    with open(an_file) as f:\n",
    "        for line in f:\n",
    "            verse, s, a = line.split()\n",
    "            yield ' '.join((verse, s, a))\n",
    "            for e in a.split('-'):\n",
    "                morphemes, functions, lex = w.analyze_word(e)\n",
    "                yield f'\\t{morphemes}'\n",
    "                yield f'\\t{functions}'\n",
    "                yield f'\\t{lex}'\n",
    "\n",
    "for i, line in enumerate(print_anfile(an_file)):\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        print ('...')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLC 0,1\tTWB\tTWB\tTWB\t-\tsp=advb\n",
      "BLC 0,1\tKTB=/~>\tKTB>\tKTB=\tnme=\"\",emf=\">\"\tsp=subs,+nu,gn=m,st=emph\n",
      "BLC 0,1\tD\tD\tD\t-\tsp=prep,ls=pcon\n",
      "BLC 0,1\tNMWS/(J~>\tNMWS>\tNMWS\tnme=\"J\",emf=\">\"\tsp=subs,nu=pl,gn=m,st=emph\n",
      "BLC 0,1\tD\tD\tD\t-\tsp=prep,ls=pcon\n",
      "BLC 0,1\t>TR/&WT=~>\t>TRWT>\t>TR\tnme=\"T=\",emf=\">\"\tsp=subs,nu=pl,gn=m,st=emph\n",
      "BLC 1,1\tMN\tMN\tMN\t-\tsp=prep\n",
      "BLC 1,1\tQDM\tQDM\tQDM\t-\tsp=prep\n",
      "BLC 1,1\tJWM/T=~>\tJWMT>\tJWM\tnme=\"T=\",emf=\">\"\tsp=subs,nu=pl,gn=m,st=emph\n",
      "BLC 1,1\t<L=[/JN\t<LJN\t<L=\tvbe=\"\",nme=\"JN\"\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=pe,vt=ptc\n",
      "BLC 1,1\tHWJ[N\tHWJN\tHWJ\tvbe=\"N\"\tnu=pl,sp=verb,vo=act,vs=pe,vt=pf,ps=first,ls=vbex\n",
      "BLC 1,1\tL\tL\tL\t-\tsp=prep\n",
      "BLC 1,1\t!M!S<R=[/\tMS<R\tS<R=\tpfm=\"M\",vbe=\"\",nme=\"\"\tsp=verb,+st,vo=act,vs=pe,vt=inf\n",
      "BLC 1,1\tL\tL\tL\t-\tsp=prep\n",
      "BLC 1,1\tCMCGRM/\tCMCGRM\tCMCGRM\tnme=\"\"\tsp=subs,+nu,+gn,st=abs,ls=prop\n",
      "BLC 1,1\t>X/&W\t>XW\t>X\tnme=\"\"\tsp=subs,+nu,+gn,+st\n",
      "BLC 1,1\tN\tN\tN\t-\tnu=pl,ps=first,sp=pron,ls=pers\n",
      "BLC 1,1\tW\tW\tW\t-\tsp=conj\n",
      "BLC 1,1\t>T(J&>[\t>T>\t>TJ\tvbe=\"\"\tnu=sg,gn=m,sp=verb,vo=act,vs=pe,vt=pf,ps=third\n",
      "BLC 1,1\t]>]CKX[\t>CKX\tCKX\tvbs=\">\",vbe=\"\"\tnu=sg,gn=m,sp=verb,vo=act,vs=af,vt=pf,ps=third\n",
      "BLC 1,1\tN\tN\tN\t-\tnu=pl,ps=first,sp=pron,ls=pers\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# toon output als in dmp-file:\n",
    "def dump_anfile(an_file):\n",
    "    with open(an_file) as f:\n",
    "        for line in f:\n",
    "            verse, s, a = line.split()\n",
    "            heading = f'BLC {verse}'\n",
    "            for e in a.split('-'):\n",
    "                morphemes, functions, lex = w.analyze_word(e)\n",
    "                surface_form = ''.join((m[1][1] for m in morphemes if m[0] != 'vpm'))\n",
    "                lexeme = dict(morphemes)['lex'][0]\n",
    "                affixes = [m for m in morphemes if m[0] != 'lex'] # TODO affix may not be the right term?\n",
    "                affix_str = ('-' if not affixes else\n",
    "                    ','.join((f'{e[0]}=\"{e[1][0]}\"' if e[0] != 'vpm' else f'{e[0]}={e[1][0]}' for e in affixes)))\n",
    "                func_str = ','.join(('+'+fn if fv is None else fn+'='+fv for fn, fv in functions if fv != False))\n",
    "\n",
    "                yield '\\t'.join((heading, e, surface_form, lexeme, affix_str, func_str))\n",
    "\n",
    "for i, line in enumerate(dump_anfile(an_file)):\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        print ('...')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om te controleren dat de output correct is heb ik bovenstaande output vergeleken met de bestaande .dmp-bestanden. Omdat de volgorde van de waarden willekeurig lijkt te zijn - of in ieder geval niet in alle gevallen gelijk - moeten alle waarden gesorteerd worden voor ze vergeleken kunnen worden, een eenvoudige diff volstaat niet. Onderstaand script bevestigt dat bovenstaande output, op de volgorde na, een exacte weergave is van de bestaande .dmp-bestanden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmp_file = filepath('../../data/blc/Laws.dmp')\n",
    "dmp_gen = dump_anfile(an_file)\n",
    "\n",
    "with open(dmp_file) as f_dmp:\n",
    "    for line1, line2 in zip(f_dmp, dmp_gen):\n",
    "        for f1, f2 in zip(line1.strip().split('\\t'), line2.split('\\t')):\n",
    "            f1s, f2s = (','.join(sorted(f.split(','))) for f in (f1,f2))\n",
    "            if f1s != f2s:\n",
    "                print(f'{line1}!=\\n{line2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

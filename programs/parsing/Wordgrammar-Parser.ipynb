{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Een parser-generator voor de wordgrammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de ETCBC-data wordt een morphologische analyse-annotatie gebruikt, die per project kan worden gedefinieerd in een `word_grammar`-definitiebestand. Per project moet er eerst een annotatieparser worden gegenereerd aan de hand van het `word-grammar`-bestand. Dat gebeurt in de `WordGrammar` class in `wrdgrm.py`, die afhankelijk is van de parser-generator in de `wgr.py` en `yapps-runtime.py` modules. De parser-generator is gegenereerd met Yapps2 (zie de website: http://theory.stanford.edu/~amitp/yapps/ en https://github.com/smurfix/yapps).\n",
    "\n",
    "Om een `WordGrammar`-object te maken zijn een `word_grammar`-bestand en een `lexicon`-bestand vereist. Vervolgens kunnen woorden geanalyseerd worden met de method `WordGrammar.analyze(word)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eerst modules importeren\n",
    "import os\n",
    "from wrdgrm import WordGrammar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-token",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "hulpfunctie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filepath(rel_path):\n",
    "    return os.path.realpath(os.path.join(os.getcwd(), rel_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestandslocaties\n",
    "lexicon_file = filepath(\"../../data/blc/syrlex\")\n",
    "word_grammar_file = filepath(\"../../data/blc/syrwgr\")\n",
    "an_file = filepath(\"../../data/blc/Laws.an\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dan kan de wordgrammar worden geïnitialiseerd\n",
    "wg = WordGrammar(word_grammar_file, lexicon_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De method `analyze()` retourneert een `Word`-object met de analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wrdgrm.Word at 0x7f6f646c8208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrdgrm.Word object\n",
    "wg.analyze(\">TR/&WT=~>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morphemes:      (('lex', ('>TR', '>TR', '>TR')), ('nme', ('T=', 'WT', '&WT=')), ('emf', ('>', '>', '>')))\n",
      "Functions:      (('vt', False), ('vs', False), ('ps', False), ('sp', 'subs'), ('nu', 'pl'), ('gn', 'm'), ('st', 'emph'))\n",
      "Lexicon:        ('17789', (('sp', 'subs'), ('gn', 'm'), ('gl', 'place, region')))\n",
      "Lexeme:         >TR\n",
      "Annotated word: >TR/&WT=~>\n",
      "Meta form:      >TR&WT=>\n",
      "Surface form:   >TRWT>\n",
      "Paradigmatic form: >TRT=>\n"
     ]
    }
   ],
   "source": [
    "# voorbeeld\n",
    "word = wg.analyze(\">TR/&WT=~>\")\n",
    "print(\n",
    "    \"{:15}\".format(\"Morphemes:\"),\n",
    "    tuple((m.mt.ident, (m.p, m.s, m.a)) for m in word.morphemes),\n",
    ")\n",
    "print(\"{:15}\".format(\"Functions:\"), word.functions)\n",
    "print(\"{:15}\".format(\"Lexicon:\"), word.lex)\n",
    "print(\"{:15}\".format(\"Lexeme:\"), word.lexeme)\n",
    "print(\"{:15}\".format(\"Annotated word:\"), word.word)\n",
    "print(\"{:15}\".format(\"Meta form:\"), word.meta_form)\n",
    "print(\"{:15}\".format(\"Surface form:\"), word.surface_form)\n",
    "print(\"{:15}\".format(\"Paradigmatic form:\"), word.paradigmatic_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naast verschillende `string`-weergaven van het geanalyseerde woord bevat het `Word`-object drie `tuples`: `morphemes`, `functions` en `lex`, met daarin de belangrijkste analyses.\n",
    "\n",
    "De eerste, `morphemes`, bevat een tuple met alle gevonden morfemen, elk als een ~~tuple met drie strings~~ `Morpheme` object met vier attributen: `mt`, een namedtuple met informatie over het morfeemtype; `p`, de paradigmatische vorm (zoals die in het lexicon staat); `s`, de oppervlaktevorm (zoals die in de tekst staat); en `a`, de geannoteerde vorm met meta-karakters.\n",
    "\n",
    "De tweede, `functions`, bevat de grammaticale functies van het woord, zoals die in de `wordgrammar` gedefinieerd zijn: `ps: \"person\"`, `nu: \"number\"`, `gn: \"gender\"`, `ls: \"lexical set\"`, `sp: \"part of speech\"`, `st: \"state\"`, `vo: \"voice\"`, `vs: \"verbal stem\"`, `vt: \"verbal tense\"`. Een veld met de waarde `False` geeft aan dat deze functie niet van toepassing is op dit woord, een veld met waarde `None` geeft aan dat de waarde niet is vastgesteld.\n",
    "\n",
    "De derde, `lex`, bevat het lemma zoals dat in het lexicon staat, met als eerste het woord-id, en vervolgens de annotaties. Behalve standaard-waarden voor de grammaticale functies bevat het lexicon een `gl`-veld voor ieder woord (gloss), en soms een `de`-veld (derived form). (In één resp. twee gevallen komen ook de velden `cs` en `ln` voor, waarvan de betekenis mij niet duidelijk is.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laws 0,1\tTWB\tTWB\tTWB\t-\tsp=advb\n",
      "Laws 0,1\tKTB=/~>\tKTB>\tKTB=\tnme=\"\",emf=\">\"\tsp=subs,+nu,gn=m,st=emph\n",
      "Laws 0,1\tD\tD\tD\t-\tsp=prep,ls=pcon\n",
      "Laws 0,1\tNMWS/(J~>\tNMWS>\tNMWS\tnme=\"J\",emf=\">\"\tsp=subs,nu=pl,gn=m,st=emph\n",
      "Laws 0,1\tD\tD\tD\t-\tsp=prep,ls=pcon\n",
      "Laws 0,1\t>TR/&WT=~>\t>TRWT>\t>TR\tnme=\"T=\",emf=\">\"\tsp=subs,nu=pl,gn=m,st=emph\n",
      "Laws 1,1\tMN\tMN\tMN\t-\tsp=prep\n",
      "Laws 1,1\tQDM\tQDM\tQDM\t-\tsp=prep\n",
      "Laws 1,1\tJWM/T=~>\tJWMT>\tJWM\tnme=\"T=\",emf=\">\"\tsp=subs,nu=pl,gn=m,st=emph\n",
      "Laws 1,1\t<L=[/JN\t<LJN\t<L=\tvbe=\"\",nme=\"JN\"\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=pe,vt=ptc\n",
      "Laws 1,1\tHWJ[N\tHWJN\tHWJ\tvbe=\"N\"\tnu=pl,sp=verb,vo=act,vs=pe,vt=pf,ps=first,ls=vbex\n",
      "Laws 1,1\tL\tL\tL\t-\tsp=prep\n",
      "Laws 1,1\t!M!S<R=[/\tMS<R\tS<R=\tpfm=\"M\",vbe=\"\",nme=\"\"\tsp=verb,+st,vo=act,vs=pe,vt=inf\n",
      "Laws 1,1\tL\tL\tL\t-\tsp=prep\n",
      "Laws 1,1\tCMCGRM/\tCMCGRM\tCMCGRM\tnme=\"\"\tsp=subs,+nu,+gn,st=abs,ls=prop\n",
      "Laws 1,1\t>X/&W\t>XW\t>X\tnme=\"\"\tsp=subs,+nu,+gn,+st\n",
      "Laws 1,1\tN\tN\tN\t-\tnu=pl,ps=first,sp=pron,ls=pers\n",
      "Laws 1,1\tW\tW\tW\t-\tsp=conj\n",
      "Laws 1,1\t>T(J&>[\t>T>\t>TJ\tvbe=\"\"\tnu=sg,gn=m,sp=verb,vo=act,vs=pe,vt=pf,ps=third\n",
      "Laws 1,1\t]>]CKX[\t>CKX\tCKX\tvbs=\">\",vbe=\"\"\tnu=sg,gn=m,sp=verb,vo=act,vs=af,vt=pf,ps=third\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# De method `dmp_str` genereert een string die overeenkomt met die in .dmp-bestanden.\n",
    "# Hieronder een voorbeeld hoe die gebruikt kan worden om een .dmp-bestand te genereren.\n",
    "# Voor een eenvoudiger manier, zie de AnParser notebook.\n",
    "\n",
    "\n",
    "def dump_anfile(name, an_file):\n",
    "    with open(an_file) as f:\n",
    "        for line in f:\n",
    "            verse, s, a = line.split()  # verse, surface form, analyzed form\n",
    "            for an_word in a.split(\"-\"):\n",
    "                word = wg.analyze(an_word)\n",
    "                yield word.dmp_str(name, verse)\n",
    "\n",
    "\n",
    "for i, line in zip(range(20), dump_anfile(\"Laws\", an_file)):\n",
    "    # for line in dump_anfile('Laws', an_file):\n",
    "    print(line)\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om te controleren dat de output correct is heb ik bovenstaande output vergeleken met de bestaande .dmp-bestanden. Omdat de volgorde van de waarden willekeurig lijkt te zijn - of in ieder geval niet in alle gevallen gelijk - moeten alle waarden gesorteerd worden voor ze vergeleken kunnen worden, een eenvoudige diff volstaat niet. Onderstaand script ~~bevestigt dat bovenstaande output, op de volgorde na, een exacte weergave is van de bestaande .dmp-bestanden~~ toont aan dat zowel de an-file als de word_grammar zijn aangepast sinds de .dmp-bestanden zijn gegenereerd:\n",
    "\n",
    "(verschillen: woorden met vpm=dp zijn nu correct als vo=pas geanalyseerd, en van `]>](NKJ[` in 15,12 en `]M]SKN[/JN` in 19.12 zijn de annotaties gewijzigd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLC 1,4\t!M!PQD[/JN:dp\tMPQDJN\tPQD\tpfm=\"M\",vbe=\"\",nme=\"JN\",vpm=dp\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 1,4\t!M!PQD[/JN:dp\tMPQDJN\tPQD\tpfm=\"M\",vbe=\"\",nme=\"JN\",vpm=dp\tsp=verb,nu=pl,gn=m,st=abs,vo=pas,vs=pa,vt=ptc\n",
      "BLC 8,20\t!M!TQN[/:dp\tMTQN\tTQN\tpfm=\"M\",vbe=\"\",nme=\"\",vpm=dp\tsp=verb,+nu,+gn,+st,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 8,20\t!M!TQN[/:dp\tMTQN\tTQN\tpfm=\"M\",vbe=\"\",nme=\"\",vpm=dp\tsp=verb,+nu,+gn,+st,vo=pas,vs=pa,vt=ptc\n",
      "BLC 10,2\t!M!CLV[/JN:dp\tMCLVJN\tCLV\tpfm=\"M\",vbe=\"\",nme=\"JN\",vpm=dp\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 10,2\t!M!CLV[/JN:dp\tMCLVJN\tCLV\tpfm=\"M\",vbe=\"\",nme=\"JN\",vpm=dp\tsp=verb,nu=pl,gn=m,st=abs,vo=pas,vs=pa,vt=ptc\n",
      "BLC 15,12\t]>](NKJ[/\t>KJ\tNKJ\tvbs=\">\",vbe=\"\",nme=\"\"\tsp=verb,+nu,+gn,+st,vo=act,vs=af\n",
      "!=\n",
      "BLC 15,12\t]>](NKJ[\t>KJ\tNKJ\tvbs=\">\",vbe=\"\"\tnu=sg,gn=m,sp=verb,vo=act,vs=af,vt=pf,ps=third\n",
      "BLC 15,12\t]>](NKJ[/\t>KJ\tNKJ\tvbs=\">\",vbe=\"\",nme=\"\"\tsp=verb,+nu,+gn,+st,vo=act,vs=af\n",
      "!=\n",
      "BLC 15,12\t]>](NKJ[\t>KJ\tNKJ\tvbs=\">\",vbe=\"\"\tnu=sg,gn=m,sp=verb,vo=act,vs=af,vt=pf,ps=third\n",
      "BLC 15,12\t]>](NKJ[/\t>KJ\tNKJ\tvbs=\">\",vbe=\"\",nme=\"\"\tsp=verb,+nu,+gn,+st,vo=act,vs=af\n",
      "!=\n",
      "BLC 15,12\t]>](NKJ[\t>KJ\tNKJ\tvbs=\">\",vbe=\"\"\tnu=sg,gn=m,sp=verb,vo=act,vs=af,vt=pf,ps=third\n",
      "BLC 16,2\t!M!CLV[/(J~>:dp\tMCLV>\tCLV\tpfm=\"M\",vbe=\"\",nme=\"J\",emf=\">\",vpm=dp\tsp=verb,nu=pl,gn=m,st=emph,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 16,2\t!M!CLV[/(J~>:dp\tMCLV>\tCLV\tpfm=\"M\",vbe=\"\",nme=\"J\",emf=\">\",vpm=dp\tsp=verb,nu=pl,gn=m,st=emph,vo=pas,vs=pa,vt=ptc\n",
      "BLC 19,8\t!M!CLV[/JN:dp\tMCLVJN\tCLV\tpfm=\"M\",vbe=\"\",nme=\"JN\",vpm=dp\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 19,8\t!M!CLV[/JN:dp\tMCLVJN\tCLV\tpfm=\"M\",vbe=\"\",nme=\"JN\",vpm=dp\tsp=verb,nu=pl,gn=m,st=abs,vo=pas,vs=pa,vt=ptc\n",
      "BLC 19,10\t!M!CLV[/JN:dp\tMCLVJN\tCLV\tpfm=\"M\",vbe=\"\",nme=\"JN\",vpm=dp\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 19,10\t!M!CLV[/JN:dp\tMCLVJN\tCLV\tpfm=\"M\",vbe=\"\",nme=\"JN\",vpm=dp\tsp=verb,nu=pl,gn=m,st=abs,vo=pas,vs=pa,vt=ptc\n",
      "BLC 19,12\t]M]SKN[/JN\tMSKNJN\tSKN\tvbs=\"M\",vbe=\"\",nme=\"JN\"\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=af\n",
      "!=\n",
      "BLC 19,12\t!M!](M]SKN[/JN\tMSKNJN\tSKN\tpfm=\"M\",vbs=\"M\",vbe=\"\",nme=\"JN\"\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=af,vt=ptc\n",
      "BLC 19,12\t]M]SKN[/JN\tMSKNJN\tSKN\tvbs=\"M\",vbe=\"\",nme=\"JN\"\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=af\n",
      "!=\n",
      "BLC 19,12\t!M!](M]SKN[/JN\tMSKNJN\tSKN\tpfm=\"M\",vbs=\"M\",vbe=\"\",nme=\"JN\"\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=af,vt=ptc\n",
      "BLC 19,12\t]M]SKN[/JN\tMSKNJN\tSKN\tvbs=\"M\",vbe=\"\",nme=\"JN\"\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=af\n",
      "!=\n",
      "BLC 19,12\t!M!](M]SKN[/JN\tMSKNJN\tSKN\tpfm=\"M\",vbs=\"M\",vbe=\"\",nme=\"JN\"\tsp=verb,nu=pl,gn=m,st=abs,vo=act,vs=af,vt=ptc\n",
      "BLC 21,12\t!M!R(W&JM[/(J~>:dp\tMRJM>\tRWM\tpfm=\"M\",vbe=\"\",nme=\"J\",emf=\">\",vpm=dp\tsp=verb,nu=pl,gn=m,st=emph,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 21,12\t!M!R(W&JM[/(J~>:dp\tMRJM>\tRWM\tpfm=\"M\",vbe=\"\",nme=\"J\",emf=\">\",vpm=dp\tsp=verb,nu=pl,gn=m,st=emph,vo=pas,vs=pa,vt=ptc\n",
      "BLC 30,9\t!M!NPQ[/(J~>:dp\tMNPQ>\tNPQ\tpfm=\"M\",vbe=\"\",nme=\"J\",emf=\">\",vpm=dp\tsp=verb,nu=pl,gn=m,st=emph,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 30,9\t!M!NPQ[/(J~>:dp\tMNPQ>\tNPQ\tpfm=\"M\",vbe=\"\",nme=\"J\",emf=\">\",vpm=dp\tsp=verb,nu=pl,gn=m,st=emph,vo=pas,vs=pa,vt=ptc\n",
      "BLC 41,2\t!M!PLG[/>:dp\tMPLG>\tPLG\tpfm=\"M\",vbe=\"\",nme=\">\",vpm=dp\tsp=verb,nu=sg,gn=f,st=abs,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 41,2\t!M!PLG[/>:dp\tMPLG>\tPLG\tpfm=\"M\",vbe=\"\",nme=\">\",vpm=dp\tsp=verb,nu=sg,gn=f,st=abs,vo=pas,vs=pa,vt=ptc\n",
      "BLC 43,5\t!M!CLV[/:dp\tMCLV\tCLV\tpfm=\"M\",vbe=\"\",nme=\"\",vpm=dp\tsp=verb,+nu,+gn,+st,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 43,5\t!M!CLV[/:dp\tMCLV\tCLV\tpfm=\"M\",vbe=\"\",nme=\"\",vpm=dp\tsp=verb,+nu,+gn,+st,vo=pas,vs=pa,vt=ptc\n",
      "BLC 43,7\t!M!CLV[/:dp\tMCLV\tCLV\tpfm=\"M\",vbe=\"\",nme=\"\",vpm=dp\tsp=verb,+nu,+gn,+st,vo=act,vs=pa,vt=ptc\n",
      "!=\n",
      "BLC 43,7\t!M!CLV[/:dp\tMCLV\tCLV\tpfm=\"M\",vbe=\"\",nme=\"\",vpm=dp\tsp=verb,+nu,+gn,+st,vo=pas,vs=pa,vt=ptc\n"
     ]
    }
   ],
   "source": [
    "dmp_file = filepath(\"../../data/blc/Laws.dmp\")\n",
    "dmp_gen = dump_anfile(\"BLC\", an_file)\n",
    "\n",
    "with open(dmp_file) as f_dmp:\n",
    "    for line1, line2 in zip(f_dmp, dmp_gen):\n",
    "        for f1, f2 in zip(line1.strip().split(\"\\t\"), line2.split(\"\\t\")):\n",
    "            f1s, f2s = (\",\".join(sorted(f.split(\",\"))) for f in (f1, f2))\n",
    "            if f1s != f2s:\n",
    "                print(f\"{line1}!=\\n{line2}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
